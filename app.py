import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta, date
from dateutil.relativedelta import relativedelta
import os
import re
import numpy as np

# --- 1. Config ---
st.set_page_config(
    page_title="æ»¾éºµæ™ºæ…§ç‡Ÿé‹å ±è¡¨",
    page_icon="ğŸœ",
    layout="wide"
)

# --- 2. Constants & Loading ---
LOCAL_DATA_DIR = "/home/eats365/data"

# Taiwan Holidays (2024-2026)
# Updated to ensure accuracy for 2026 Sept/Oct
tw_holidays = [
    # 2024
    "2024-01-01", "2024-02-08", "2024-02-09", "2024-02-10", "2024-02-11", "2024-02-12", "2024-02-13", "2024-02-14",
    "2024-02-28", "2024-04-04", "2024-04-05", "2024-05-01", "2024-06-10", "2024-09-17", "2024-10-10", "2024-12-25",
    # 2025
    "2025-01-01", "2025-01-25", "2025-01-26", "2025-01-27", "2025-01-28", "2025-01-29", "2025-01-30", "2025-01-31", 
    "2025-02-01", "2025-02-02", "2025-02-28", "2025-04-03", "2025-04-04", "2025-04-05", "2025-04-06", 
    "2025-05-01", "2025-05-31", "2025-06-01", "2025-06-02", "2025-10-04", "2025-10-05", "2025-10-06", 
    "2025-10-10", "2025-10-11", "2025-10-12", "2025-12-25",
    # 2026
    "2026-01-01", "2026-02-13", "2026-02-14", "2026-02-15", "2026-02-16", "2026-02-17", "2026-02-18",
    "2026-02-28", "2026-04-03", "2026-04-04", "2026-04-05", "2026-04-06", "2026-05-01", "2026-06-19", 
    "2026-09-25", "2026-09-26", "2026-09-27", "2026-09-28", "2026-10-09", "2026-10-10", "2026-10-11", "2026-10-24", "2026-10-25", "2026-10-26", "2026-12-25"
]
TW_HOLIDAYS_SET = set(tw_holidays)

@st.cache_data(ttl=300)
def load_data():
    local_report = os.path.join(LOCAL_DATA_DIR, "history_report.csv")
    local_details = os.path.join(LOCAL_DATA_DIR, "history_details.csv")
    
    if os.path.exists(local_report) and os.path.exists(local_details):
        df_report = pd.read_csv(local_report)
        df_details = pd.read_csv(local_details)
    else:
        return pd.DataFrame(), pd.DataFrame()
    return df_report, df_details

def clean_currency(series):
    if series.dtype == 'object':
        return pd.to_numeric(series.astype(str).str.replace(r'[NT\$,]', '', regex=True), errors='coerce').fillna(0)
    return pd.to_numeric(series, errors='coerce').fillna(0)

def preprocess_data(df_report, df_details):
    if df_report.empty or df_details.empty:
        return df_report, df_details

    # --- A. Common Cleaning ---
    if 'ç‹€æ…‹' in df_report.columns:
        df_report = df_report[~df_report['ç‹€æ…‹'].astype(str).str.contains('å–æ¶ˆ|Cancelled|å·²é—œé–‰|Closed|Void|ä½œå»¢', case=False, na=False)]
    if 'Status' in df_details.columns:
        df_details = df_details[~df_details['Status'].astype(str).str.contains('å–æ¶ˆ|Cancelled|å·²é—œé–‰|Closed|Void|ä½œå»¢', case=False, na=False)]

    if 'date' in df_report.columns:
        df_report['Date_Parsed'] = pd.to_datetime(df_report['date'], errors='coerce')
    if 'date' in df_details.columns:
        df_details['Date_Parsed'] = pd.to_datetime(df_details['date'], errors='coerce')

    # Combine DateTime
    if 'æ™‚é–“' in df_report.columns and 'Date_Parsed' in df_report.columns:
        temp_time = pd.to_datetime(df_report['æ™‚é–“'], errors='coerce')
        time_str = temp_time.dt.strftime('%H:%M:%S').fillna('00:00:00')
        df_report['Datetime'] = pd.to_datetime(
            df_report['Date_Parsed'].dt.strftime('%Y-%m-%d') + ' ' + time_str,
            errors='coerce'
        )

    # Currency
    if 'ç¸½è¨ˆ' in df_report.columns:
        df_report['ç¸½è¨ˆ'] = clean_currency(df_report['ç¸½è¨ˆ'])
    if 'Order Total(TWD)' in df_details.columns:
        df_details['Order Total(TWD)'] = clean_currency(df_details['Order Total(TWD)'])
    if 'Item Amount(TWD)' in df_details.columns:
        df_details['Item Amount(TWD)'] = clean_currency(df_details['Item Amount(TWD)'])
    if 'Item Quantity' in df_details.columns:
        df_details['Item Quantity'] = pd.to_numeric(df_details['Item Quantity'], errors='coerce').fillna(0)

    # --- Deduplicate Modifier Rows ---
    if 'Modifier Name' in df_details.columns:
        df_details = df_details[df_details['Modifier Name'].isna() | (df_details['Modifier Name'] == '')]

    # --- Feature: Aggregate "Super Value Combos" ---
    if 'Item Name' in df_details.columns:
        mask_combo = df_details['Item Name'].astype(str).str.contains('è¶…å€¼çµ„åˆ', na=False)
        df_details.loc[mask_combo, 'Item Name'] = 'è¶…å€¼çµ„åˆ'
    
    # --- Categorization P14 Specific Items ---
    clean_cols = {c: c.strip() for c in df_details.columns}
    df_details.rename(columns=clean_cols, inplace=True)
    
    def infer_category(row):
        sku = str(row.get('Product SKU', '')).strip().upper()
        name = str(row.get('Item Name', '')).strip()
        
        # 0. User Forced Specific Items (P14)
        if name in ['æ‹Œæ°´è“®', 'ç‡™å¤§é™¸å¦¹', 'ç‡™é«˜éº—èœ', 'ç‡™é’æ±Ÿèœ']: return 'C é’èœ (Vegetables)'
        if name in ['æ¡‚èŠ±é¦™è±†ä¹¾', 'æ¶¼æ‹Œè±†å¹²çµ²', 'ç‡’æ¤’å°¬çš®è›‹', 'ç´…ç‡’èŒ„å­å›']: return 'D å°èœ (Sides)'

        # 1. Special Cases C-1
        if name in ['è”¥æ²¹é›', 'èŠ­æ¨‚é‡è¦‹äº”èŠ±']: return 'C-1 ç‰¹æ®Šå–®é» (Special)'
        if name == 'è¶…å€¼çµ„åˆ': return 'S å¥—é¤ (Set)'

        # 2. Priority: Check SKU First Letter
        if len(sku) > 0:
            prefix = sku[0]
            if prefix == 'A': return 'A æ¹¯éºµ (Soup Noodle)'
            if prefix == 'B': return 'B ä¹¾éºµ/é£¯ (Dry/Rice)'
            if prefix == 'E': return 'E æ¹¯å“ (Soup)' 
            
            # P15 Fix: Cross-Map SKU C->Sides, D->Veg (User Request 1578)
            if prefix == 'C': return 'D å°èœ (Sides)' 
            if prefix == 'D': return 'C é’èœ (Vegetables)' 
            if prefix == 'F': return 'F é£²æ–™ (Drinks)'
            
            if prefix == 'S': return 'S å¥—é¤ (Set)'

        # 3. Fallback (Name based)
        item_type = str(row.get('Item Type', ''))
        if 'Set Meal' in item_type or 'Combo Item' in item_type:
             if 'Single Item' not in item_type: return 'S å¥—é¤ (Set)'
        
        if 'æ¹¯éºµ' in name: return 'A æ¹¯éºµ (Soup Noodle)'
        if 'æ‹Œéºµ' in name or 'ä¹¾éºµ' in name or 'é£¯' in name: return 'B ä¹¾éºµ/é£¯ (Dry/Rice)'
        
        if any(x in name for x in ['æ¹¯', 'ç¾¹']): return 'E æ¹¯å“ (Soup)'
        
        # Consistent with SKU P15
        if any(x in name for x in ['èœ', 'æ°´è“®']): return 'C é’èœ (Vegetables)'
        if any(x in name for x in ['è±†å¹²', 'çš®è›‹', 'è±†è…', 'æµ·å¸¶', 'èŠ±ç”Ÿ', 'æ¯›è±†', 'é»ƒç“œ', 'è›‹']): return 'D å°èœ (Sides)'
        
        if any(x in name for x in ['èŒ¶', 'é£²', 'å¯æ¨‚', 'é›ªç¢§']): return 'F é£²æ–™ (Drinks)'
        
        return 'G å…¶ä»– (Others)'
        
    df_details['Category'] = df_details.apply(infer_category, axis=1)

    # --- Day Type ---
    def get_day_type(dt):
        if pd.isnull(dt): return 'Unknown'
        d_str = dt.strftime('%Y-%m-%d')
        if d_str in TW_HOLIDAYS_SET: return 'å‡æ—¥ (Holiday)' 
        if dt.weekday() >= 5: return 'å‡æ—¥ (Holiday)' 
        return 'å¹³æ—¥ (Weekday)'
    df_report['Day_Type'] = df_report['Date_Parsed'].apply(get_day_type)
    
    # --- Period ---
    def get_period(dt):
        if pd.isnull(dt): return 'Unknown'
        return 'ä¸­åˆ (Lunch)' if dt.hour < 16 else 'æ™šä¸Š (Dinner)'
    df_report['Period'] = df_report['Datetime'].apply(get_period) if 'Datetime' in df_report.columns else 'Unknown'

    # --- Main Dish Logic ---
    df_details['Is_Main_Dish'] = False
    mask_name = df_details['Item Name'].astype(str).str.contains('éºµ|é£¯', regex=True, na=False)
    mask_exclude_wrapper = pd.Series([True] * len(df_details))
    if 'Item Type' in df_details.columns:
        mask_is_wrapper = df_details['Item Type'].astype(str).str.fullmatch('Combo Item', case=False, na=False)
        mask_exclude_wrapper = ~mask_is_wrapper
    df_details.loc[mask_name & mask_exclude_wrapper, 'Is_Main_Dish'] = True

    return df_report, df_details

def calculate_delta(current, previous):
    if previous == 0: return None
    return (current - previous) / previous

# --- Prediction Logic P13 ---
def predict_revenue_summary(df_report, days_back=14):
    end_date = df_report['Date_Parsed'].max()
    start_date = end_date - timedelta(days=days_back)
    mask = (df_report['Date_Parsed'] >= start_date) & (df_report['Date_Parsed'] <= end_date)
    recent = df_report[mask].copy()

    def get_simple_type(dt):
        d_str = dt.strftime('%Y-%m-%d')
        if d_str in TW_HOLIDAYS_SET or dt.weekday() >= 5: return 'Holiday'
        return 'Weekday'
    recent['Simple'] = recent['Date_Parsed'].apply(get_simple_type)
    
    daily_sums = recent.groupby(['Date_Parsed', 'Simple'])['ç¸½è¨ˆ'].sum().reset_index()
    avgs = daily_sums.groupby('Simple')['ç¸½è¨ˆ'].mean()
    
    avg_wd = avgs.get('Weekday', 0)
    avg_hd = avgs.get('Holiday', 0)
    
    if avg_wd == 0 and avg_hd > 0: avg_wd = avg_hd
    if avg_hd == 0 and avg_wd > 0: avg_hd = avg_wd
    
    return avg_wd, avg_hd

def predict_monthly_table_hybrid(avg_wd, avg_hd, df_report, months=12):
    # Hybrid: For current month (if partial data exists), sum Actual + Forecast Remainder
    # For future months, pure Forecast
    
    latest_date = df_report['Date_Parsed'].max()
    start_forecast_date = latest_date + timedelta(days=1)
    end_forecast_date = start_forecast_date + relativedelta(months=months)
    
    dates = []
    curr = start_forecast_date
    while curr < end_forecast_date:
        dates.append(curr)
        curr += timedelta(days=1)
        
    df_future = pd.DataFrame({'Date': dates})
    df_future['Month'] = df_future['Date'].dt.to_period('M')
    
    def get_simple_type(dt):
        d_str = dt.strftime('%Y-%m-%d')
        if d_str in TW_HOLIDAYS_SET or dt.weekday() >= 5: return 'Holiday'
        return 'Weekday'

    df_future['Type'] = df_future['Date'].apply(get_simple_type)
    
    # Group Future by Month
    future_stats = []
    groups = df_future.groupby('Month')
    for m, group in groups:
        n_wd = (group['Type'] == 'Weekday').sum()
        n_hd = (group['Type'] == 'Holiday').sum()
        rev = (n_wd * avg_wd) + (n_hd * avg_hd)
        future_stats.append({
            'Month_Period': m,
            'Date_Label': str(m),
            'Weekday Days': n_wd,
            'Holiday Days': n_hd,
            'Forecast Revenue': rev,
            'Status': 'Forecast'
        })
    df_future_agg = pd.DataFrame(future_stats)
    
    # Get Current Month Actuals
    current_month_period = latest_date.to_period('M')
    
    # Calculate Actuals for Current Month
    current_month_start = latest_date.replace(day=1)
    mask_cur = (df_report['Date_Parsed'] >= current_month_start) & (df_report['Date_Parsed'] <= latest_date)
    actual_rev = df_report.loc[mask_cur, 'ç¸½è¨ˆ'].sum()
    
    # Update the Current Month row in df_future_agg
    idx = df_future_agg.index[df_future_agg['Month_Period'] == current_month_period].tolist()
    
    if idx:
        future_val = df_future_agg.loc[idx[0], 'Forecast Revenue']
        # Hybrid Total
        hybrid_total = actual_rev + future_val
        df_future_agg.loc[idx[0], 'Forecast Revenue'] = hybrid_total
        df_future_agg.loc[idx[0], 'Status'] = 'Hybrid (Actual+Fcst)'
    else:
        # If today is month end, we might not have a future date for this month.
        pass

    return df_future_agg

# --- 3. Main App ---
try:
    with st.spinner('æ•¸æ“šè™•ç†ä¸­...'):
        df_report_raw, df_details_raw = load_data()
        df_report, df_details = preprocess_data(df_report_raw, df_details_raw)

    if df_report.empty:
        st.warning("å°šæœªè¼‰å…¥è³‡æ–™")
        st.stop()

    st.sidebar.title("ğŸœ æ»¾éºµ Dashboard")
    view_mode = st.sidebar.radio("åŠŸèƒ½åˆ‡æ›", ["ğŸ“Š ç‡Ÿé‹ç¸½è¦½", "ğŸŸ å•†å“åˆ†æ", "ğŸ‘¥ æœƒå“¡æŸ¥è©¢", "ğŸ†• æ–°èˆŠå®¢åˆ†æ", "ğŸ”® æ™ºæ…§é æ¸¬"])
    st.sidebar.divider()

    st.sidebar.header("ğŸ“… æ—¥æœŸç¯©é¸")
    today = date.today()
    month_options = [ (today - relativedelta(months=i)).strftime("%Y-%m") for i in range(6) ]
    filter_opts = ["ä»Šæ—¥ (Today)", "æ˜¨æ—¥ (Yesterday)", "æœ¬é€± (This Week)", "æœ¬æœˆ (This Month)", 
                   "è¿‘ 28 å¤©", "è¿‘ 30 å¤©", "è¿‘ 2 å€‹æœˆ (60 Days)", "è¿‘ 6 å€‹æœˆ (180 Days)", "è‡ªè¨‚ç¯„åœ"] + month_options
    filter_mode = st.sidebar.selectbox("å¿«é€Ÿå€é–“", filter_opts, index=3)

    start_date, end_date = today, today 
    if filter_mode == "ä»Šæ—¥ (Today)": start_date = end_date = pd.Timestamp(today)
    elif filter_mode == "æ˜¨æ—¥ (Yesterday)": start_date = end_date = pd.Timestamp(today - timedelta(days=1))
    elif filter_mode == "æœ¬é€± (This Week)": start_date = pd.Timestamp(today - timedelta(days=today.weekday())); end_date = pd.Timestamp(today)
    elif filter_mode == "æœ¬æœˆ (This Month)": start_date = pd.Timestamp(today.replace(day=1)); end_date = pd.Timestamp(today)
    elif filter_mode == "è¿‘ 28 å¤©": start_date = pd.Timestamp(today - timedelta(days=28)); end_date = pd.Timestamp(today)
    elif filter_mode == "è¿‘ 30 å¤©": start_date = pd.Timestamp(today - timedelta(days=30)); end_date = pd.Timestamp(today)
    elif filter_mode == "è¿‘ 2 å€‹æœˆ (60 Days)": start_date = pd.Timestamp(today - timedelta(days=60)); end_date = pd.Timestamp(today)
    elif filter_mode == "è¿‘ 6 å€‹æœˆ (180 Days)": start_date = pd.Timestamp(today - timedelta(days=180)); end_date = pd.Timestamp(today)
    elif filter_mode in month_options: y, m = map(int, filter_mode.split('-')); start_date = pd.Timestamp(date(y, m, 1)); end_date = pd.Timestamp(start_date + relativedelta(months=1, days=-1))
    else: d = st.sidebar.date_input("é¸æ“‡æ—¥æœŸ", [today - timedelta(days=7), today]); start_date = pd.to_datetime(d[0]) if len(d) > 0 else pd.Timestamp(today); end_date = pd.to_datetime(d[1]) if len(d) > 1 else start_date

    mask_rep = (df_report['Date_Parsed'] >= start_date) & (df_report['Date_Parsed'] <= end_date)
    df_rep = df_report.loc[mask_rep].copy()
    mask_det = (df_details['Date_Parsed'] >= start_date) & (df_details['Date_Parsed'] <= end_date)
    df_det = df_details.loc[mask_det].copy()

    prev_end = start_date - timedelta(days=1)
    duration = end_date - start_date
    prev_start = prev_end - duration
    mask_rep_prev = (df_report['Date_Parsed'] >= prev_start) & (df_report['Date_Parsed'] <= prev_end)
    df_rep_prev = df_report.loc[mask_rep_prev].copy()
    mask_det_prev = (df_details['Date_Parsed'] >= prev_start) & (df_details['Date_Parsed'] <= prev_end)
    df_det_prev = df_details.loc[mask_det_prev].copy()

    # --- VIEW 1: ç‡Ÿé‹ç¸½è¦½ ---
    if view_mode == "ğŸ“Š ç‡Ÿé‹ç¸½è¦½":
        st.title(f"ğŸ“Š ç‡Ÿé‹ç¸½è¦½ ({start_date.date()} ~ {end_date.date()})")
        
        curr_rev = df_rep['ç¸½è¨ˆ'].sum()
        prev_rev = df_rep_prev['ç¸½è¨ˆ'].sum()
        curr_vis = df_det[df_det['Is_Main_Dish']]['Item Quantity'].sum()
        prev_vis = df_det_prev[df_det_prev['Is_Main_Dish']]['Item Quantity'].sum()
        curr_txs = len(df_rep)
        prev_txs = len(df_rep_prev)
        curr_avg = curr_rev / curr_vis if curr_vis > 0 else 0
        prev_avg = prev_rev / prev_vis if prev_vis > 0 else 0

        c1, c2, c3, c4 = st.columns(4)
        c1.metric("ğŸ’°ç¸½ç‡Ÿæ¥­é¡", f"${curr_rev:,.0f}", f"{calculate_delta(curr_rev, prev_rev):.1%}" if prev_rev else None)
        c2.metric("ğŸœä¾†å®¢æ•¸", f"{curr_vis:,.0f}", f"{calculate_delta(curr_vis, prev_vis):.1%}" if prev_vis else None)
        c3.metric("ğŸ§¾è¨‚å–®æ•¸", f"{curr_txs:,.0f}", f"{calculate_delta(curr_txs, prev_txs):.1%}" if prev_txs else None)
        c4.metric("ğŸ‘¤å¹³å‡å®¢å–®åƒ¹", f"${curr_avg:,.0f}", f"{calculate_delta(curr_avg, prev_avg):.1%}" if prev_avg else None)
        st.divider()

        ov_int = st.radio("åœ–è¡¨å–®ä½", ["å¤© (Daily)", "é€± (Weekly)", "4é€± (Monthly)"], horizontal=True, key='ov_int')
        ov_freq = 'D'
        if ov_int == "é€± (Weekly)": ov_freq = 'W-MON'
        elif ov_int == "4é€± (Monthly)": ov_freq = 'M'

        col_L, col_R = st.columns([2, 1])
        with col_L:
            st.subheader("ğŸ“ˆ ç‡Ÿæ¥­é¡è¶¨å‹¢ (æ™‚æ®µ)")
            if not df_rep.empty:
                if ov_freq == 'D':
                    daily_period = df_rep.groupby(['Date_Parsed', 'Period'])['ç¸½è¨ˆ'].sum().reset_index()
                    daily_total = df_rep.groupby('Date_Parsed')['ç¸½è¨ˆ'].sum().reset_index().rename(columns={'ç¸½è¨ˆ': 'Daily_Total'})
                    daily_period = pd.merge(daily_period, daily_total, on='Date_Parsed', how='left')
                    fig = px.bar(daily_period, x='Date_Parsed', y='ç¸½è¨ˆ', color='Period', barmode='stack', color_discrete_map={'ä¸­åˆ (Lunch)': '#FFC107', 'æ™šä¸Š (Dinner)': '#3F51B5'}, custom_data=['Daily_Total'])
                    fig.update_traces(hovertemplate="Date: %{x}<br>Rev: $%{y:,.0f}<br>Total: $%{customdata[0]:,.0f}")
                else:
                    resampled = df_rep.set_index('Date_Parsed').resample(ov_freq)['ç¸½è¨ˆ'].sum().reset_index()
                    fig = px.bar(resampled, x='Date_Parsed', y='ç¸½è¨ˆ', title=f"ç‡Ÿæ¥­é¡ ({ov_int})")
                st.plotly_chart(fig, use_container_width=True)
        with col_R:
            st.subheader("ğŸ“… å¹³å‡æ—¥å¹³å‡ (vs ä¸ŠæœŸ)")
            if not df_rep.empty:
                daily_rev = df_rep.groupby(['Date_Parsed', 'Day_Type'])['ç¸½è¨ˆ'].sum().reset_index()
                curr_type_avg = daily_rev.groupby('Day_Type')['ç¸½è¨ˆ'].mean()
                daily_rev_prev = df_rep_prev.groupby(['Date_Parsed', 'Day_Type'])['ç¸½è¨ˆ'].sum().reset_index() if not df_rep_prev.empty else pd.DataFrame()
                prev_type_avg = daily_rev_prev.groupby('Day_Type')['ç¸½è¨ˆ'].mean() if not daily_rev_prev.empty else pd.Series()
                for dtype in ['å¹³æ—¥ (Weekday)', 'å‡æ—¥ (Holiday)']:
                    val = curr_type_avg.get(dtype, 0)
                    pval = prev_type_avg.get(dtype, 0)
                    st.metric(f"å¹³å‡ {dtype}", f"${val:,.0f}", f"{calculate_delta(val, pval):.1%}" if pval else None)

        st.divider()
        st.subheader("ğŸ›µ æ¯æ—¥ç‡Ÿæ”¶çµæ§‹ (é€šè·¯)")
        col_type = 'å–®é¡å‹' if 'å–®é¡å‹' in df_rep.columns else 'Order Type'
        if col_type in df_rep.columns:
            if ov_freq == 'D':
                 daily_type = df_rep.groupby(['Date_Parsed', col_type])['ç¸½è¨ˆ'].sum().reset_index()
            else:
                 daily_type = df_rep.set_index('Date_Parsed').groupby(col_type).resample(ov_freq)['ç¸½è¨ˆ'].sum().reset_index()
            
            fig_type = px.bar(daily_type, x='Date_Parsed', y='ç¸½è¨ˆ', color=col_type, barmode='stack')
            st.plotly_chart(fig_type, use_container_width=True)

        st.divider()
        c_vis, c_atv = st.columns(2)
        with c_vis:
            st.subheader("ğŸ‘¥ ä¾†å®¢æ•¸è¶¨å‹¢")
            if not df_rep.empty:
                daily_vis = df_det[df_det['Is_Main_Dish']].set_index('Date_Parsed').resample(ov_freq)['Item Quantity'].sum().reset_index()
                fig_v = px.line(daily_vis, x='Date_Parsed', y='Item Quantity', markers=True, title=f"ä¾†å®¢æ•¸ ({ov_int})")
                st.plotly_chart(fig_v, use_container_width=True)
        with c_atv:
            st.subheader("ğŸ’° å®¢å–®åƒ¹è¶¨å‹¢")
            if not df_rep.empty:
                res_rev = df_rep.set_index('Date_Parsed').resample(ov_freq)['ç¸½è¨ˆ'].sum()
                res_vis = df_det[df_det['Is_Main_Dish']].set_index('Date_Parsed').resample(ov_freq)['Item Quantity'].sum()
                df_atv = pd.DataFrame({'Rev': res_rev, 'Vis': res_vis})
                df_atv['ATV'] = df_atv['Rev'] / df_atv['Vis']
                df_atv = df_atv.reset_index()
                fig_a = px.line(df_atv, x='Date_Parsed', y='ATV', markers=True, title=f"å®¢å–®åƒ¹ ({ov_int})")
                st.plotly_chart(fig_a, use_container_width=True)
        
        st.divider()
        st.subheader("ğŸ“‹ ç‡Ÿé‹å ±è¡¨ (Table)")
        if not df_rep.empty:
            cols_to_agg = {'ç¸½è¨ˆ': 'sum'}
            if ov_freq == 'D':
                grouped = df_rep.groupby('Date_Parsed')
                base_agg = grouped['ç¸½è¨ˆ'].sum().reset_index().rename(columns={'ç¸½è¨ˆ': 'ç¸½ç‡Ÿæ¥­é¡'})
                base_agg['Date_Label'] = base_agg['Date_Parsed'].dt.date.astype(str)
            else:
                grouped = df_rep.set_index('Date_Parsed').resample(ov_freq)
                base_agg = grouped['ç¸½è¨ˆ'].sum().reset_index().rename(columns={'ç¸½è¨ˆ': 'ç¸½ç‡Ÿæ¥­é¡'})
                base_agg['Date_Label'] = base_agg['Date_Parsed'].dt.strftime('%Y-%m-%d (Start)')

            if ov_freq == 'D':
                period_rev = df_rep.groupby(['Date_Parsed', 'Period'])['ç¸½è¨ˆ'].sum().unstack(fill_value=0)
            else:
                p_groups = []
                for p in ['ä¸­åˆ (Lunch)', 'æ™šä¸Š (Dinner)']:
                    mask_p = df_rep['Period'] == p
                    if mask_p.any():
                        res = df_rep[mask_p].set_index('Date_Parsed').resample(ov_freq)['ç¸½è¨ˆ'].sum()
                        res.name = p
                        p_groups.append(res)
                if p_groups: period_rev = pd.concat(p_groups, axis=1).fillna(0)
                else: period_rev = pd.DataFrame()

            period_rev = period_rev.reset_index()
            period_rev.rename(columns={'ä¸­åˆ (Lunch)': 'åˆé¤ç‡Ÿæ”¶', 'æ™šä¸Š (Dinner)': 'æ™šé¤ç‡Ÿæ”¶'}, inplace=True)
            for c in ['åˆé¤ç‡Ÿæ”¶', 'æ™šé¤ç‡Ÿæ”¶']: 
                if c not in period_rev.columns: period_rev[c] = 0

            if ov_freq == 'D':
                 vis_agg = df_det[df_det['Is_Main_Dish']].groupby('Date_Parsed')['Item Quantity'].sum()
            else:
                 vis_agg = df_det[df_det['Is_Main_Dish']].set_index('Date_Parsed').resample(ov_freq)['Item Quantity'].sum()
            vis_agg = vis_agg.reset_index().rename(columns={'Item Quantity': 'ä¾†å®¢æ•¸'})

            if col_type in df_rep.columns:
                types = df_rep[col_type].unique()
                c_groups = []
                for t in types:
                    mask_t = df_rep[col_type] == t
                    if mask_t.any():
                        if ov_freq == 'D': res = df_rep[mask_t].groupby('Date_Parsed')['ç¸½è¨ˆ'].sum()
                        else: res = df_rep[mask_t].set_index('Date_Parsed').resample(ov_freq)['ç¸½è¨ˆ'].sum()
                        res.name = t
                        c_groups.append(res)
                if c_groups: channel_rev = pd.concat(c_groups, axis=1).fillna(0).reset_index()
                else: channel_rev = pd.DataFrame({'Date_Parsed': base_agg['Date_Parsed']})
            else: channel_rev = pd.DataFrame({'Date_Parsed': base_agg['Date_Parsed']})

            rename_map = {}
            for c in channel_rev.columns:
                if 'Delivery' in str(c) or 'å¤–é€' in str(c): rename_map[c] = 'å¤–é€ç‡Ÿæ”¶'
                if 'Takeout' in str(c) or 'å¤–å¸¶' in str(c): rename_map[c] = 'å¤–å¸¶ç‡Ÿæ”¶'
                if 'Dine-in' in str(c) or 'å…§ç”¨' in str(c): rename_map[c] = 'å ‚é£Ÿç‡Ÿæ”¶ (å…§ç”¨)'
            channel_rev.rename(columns=rename_map, inplace=True)

            final_df = base_agg.merge(period_rev, on='Date_Parsed', how='left')
            final_df = final_df.merge(vis_agg, on='Date_Parsed', how='left')
            final_df = final_df.merge(channel_rev, on='Date_Parsed', how='left')
            final_df['å®¢å–®åƒ¹'] = (final_df['ç¸½ç‡Ÿæ¥­é¡'] / final_df['ä¾†å®¢æ•¸']).replace([np.inf, -np.inf], 0).fillna(0).round(0)
            
            cols_show = ['Date_Label', 'åˆé¤ç‡Ÿæ”¶', 'æ™šé¤ç‡Ÿæ”¶', 'ç¸½ç‡Ÿæ¥­é¡', 'ä¾†å®¢æ•¸', 'å®¢å–®åƒ¹']
            for c in ['å¤–é€ç‡Ÿæ”¶', 'å¤–å¸¶ç‡Ÿæ”¶', 'å ‚é£Ÿç‡Ÿæ”¶ (å…§ç”¨)']:
                if c in final_df.columns: cols_show.append(c)
                
            st.dataframe(final_df[cols_show].sort_values('Date_Label', ascending=False).style.format({
                'åˆé¤ç‡Ÿæ”¶': '${:,.0f}', 'æ™šé¤ç‡Ÿæ”¶': '${:,.0f}', 'ç¸½ç‡Ÿæ¥­é¡': '${:,.0f}',
                'ä¾†å®¢æ•¸': '{:,.0f}', 'å®¢å–®åƒ¹': '${:,.0f}',
                'å¤–é€ç‡Ÿæ”¶': '${:,.0f}', 'å¤–å¸¶ç‡Ÿæ”¶': '${:,.0f}', 'å ‚é£Ÿç‡Ÿæ”¶ (å…§ç”¨)': '${:,.0f}'
            }), use_container_width=True)

    # --- VIEW 2: å•†å“åˆ†æ ---
    elif view_mode == "ğŸŸ å•†å“åˆ†æ":
        st.title("ğŸŸ å•†å“éŠ·å”®åˆ†æ")
        
        if 'Item Name' in df_det.columns:
            df_items = df_det.dropna(subset=['Item Name'])
            
            st.subheader("ğŸ“ˆ é¡åˆ¥èˆ‡å•†å“èµ°å‹¢")
            
            cats = sorted(list(df_items['Category'].unique()))
            comp_opt = "ğŸ“‹ [ç‰¹æ®Š] ä¹¾éºµ/é£¯ vs æ¹¯éºµ (Dry/Rice vs Soup)"
            cats.insert(0, comp_opt)
            
            sel_cat = st.selectbox("è«‹é¸æ“‡é¡åˆ¥ æˆ– ç‰¹æ®Šæ¯”è¼ƒ", cats, index=0)
            
            interval = st.radio("èµ°å‹¢å–®ä½", ["å¤© (Daily)", "é€± (Weekly)", "4é€± (Monthly)"], index=0, horizontal=True)
            freq_alias = 'D'
            if interval == "é€± (Weekly)": freq_alias = 'W-MON'
            elif interval == "4é€± (Monthly)": freq_alias = 'M' 

            if sel_cat == comp_opt:
                mask_a = df_items['Category'].str.contains('A æ¹¯éºµ', na=False)
                mask_b = df_items['Category'].str.contains('B ä¹¾éºµ', na=False)
                comp_df = df_items[mask_a | mask_b].copy()
                comp_df['Group'] = comp_df['Category'].apply(lambda x: 'æ¹¯éºµ (Soup)' if 'A æ¹¯éºµ' in x else 'ä¹¾éºµ/é£¯ (Dry/Rice)')
                
                chart_data = comp_df.set_index('Date_Parsed').groupby('Group').resample(freq_alias)['Item Quantity'].sum().reset_index()
                fig_trend = px.line(chart_data, x='Date_Parsed', y='Item Quantity', color='Group', markers=True, title=f"ä¹¾éºµ/é£¯ vs æ¹¯éºµ - {interval} èµ°å‹¢æ¯”è¼ƒ")
                st.plotly_chart(fig_trend, use_container_width=True)
                
                st.write("**æ¯”ä¾‹åˆ†æ (Ratio)**")
                pivot_ratio = chart_data.pivot(index='Date_Parsed', columns='Group', values='Item Quantity').fillna(0)
                pivot_ratio['Total'] = pivot_ratio.sum(axis=1)
                for g in pivot_ratio.columns:
                    if g != 'Total': pivot_ratio[g+' %'] = pivot_ratio[g] / pivot_ratio['Total']
                
                fig_ratio = px.bar(pivot_ratio.reset_index(), x='Date_Parsed', y=[c for c in pivot_ratio.columns if '%' in c], barmode='stack', title="éŠ·å”®æ¯”ä¾‹ (Share %)")
                st.plotly_chart(fig_ratio, use_container_width=True)

            else:
                cat_df = df_items[df_items['Category'] == sel_cat].copy()
                top_items = cat_df.groupby('Item Name')['Item Quantity'].sum().nlargest(5).index.tolist()
                sel_items = st.multiselect("é¸æ“‡å•†å“ç¹ªåœ–", cat_df['Item Name'].unique(), default=top_items)
                
                if sel_items:
                    chart_data = cat_df[cat_df['Item Name'].isin(sel_items)].copy()
                    chart_data = chart_data.set_index('Date_Parsed').groupby('Item Name').resample(freq_alias)['Item Quantity'].sum().reset_index()
                    fig_trend = px.line(chart_data, x='Date_Parsed', y='Item Quantity', color='Item Name', markers=True, title=f"{sel_cat} {interval} èµ°å‹¢")
                    st.plotly_chart(fig_trend, use_container_width=True)
                
                # P16: Restore Pie Chart
                st.write("**å•†å“ä½”æ¯” (Pie Chart)**")
                pie_data = cat_df.groupby('Item Name')['Item Quantity'].sum().reset_index()
                fig_pie = px.pie(pie_data, values='Item Quantity', names='Item Name', title=f"{sel_cat} éŠ·å”®ä½”æ¯”")
                st.plotly_chart(fig_pie, use_container_width=True)

    # --- VIEW 3: æœƒå“¡æŸ¥è©¢ ---
    elif view_mode == "ğŸ‘¥ æœƒå“¡æŸ¥è©¢":
        st.title("ğŸ‘¥ æœƒå“¡æ¶ˆè²»ç´€éŒ„æŸ¥è©¢")
        st.subheader("ğŸ” 1. æœå°‹æœƒå“¡")
        search_term = st.text_input("è¼¸å…¥ å§“å æˆ– é›»è©± (æ¨¡ç³Šæœå°‹)", "")
        
        col_phone = 'å®¢æˆ¶é›»è©±' if 'å®¢æˆ¶é›»è©±' in df_report.columns else 'Contact'
        col_name = 'å®¢æˆ¶å§“å' if 'å®¢æˆ¶å§“å' in df_report.columns else 'Customer Name'
        
        if search_term:
            s_clean = search_term.strip()
            if col_phone in df_report.columns:
                 phone_series = df_report[col_phone].astype(str).str.replace(r'\D', '', regex=True)
            else: phone_series = pd.Series([])
            if col_name in df_report.columns:
                 name_series = df_report[col_name].astype(str).fillna('')
            else: name_series = pd.Series([])
            
            mask = pd.Series(False, index=df_report.index)
            if not phone_series.empty: mask |= phone_series.str.contains(s_clean, na=False)
            if not name_series.empty: mask |= name_series.str.contains(s_clean, na=False)
            results = df_report[mask].copy()
            unique_members = results[[col_name, col_phone]].drop_duplicates()
            
            if not unique_members.empty:
                st.success(f"æ‰¾åˆ° {len(unique_members)} ä½ç›¸é—œæœƒå“¡")
                unique_members['Label'] = unique_members[col_name].astype(str) + " (" + unique_members[col_phone].astype(str) + ")"
                sel_member_label = st.selectbox("è«‹é¸æ“‡:", unique_members['Label'].tolist())
                sel_row = unique_members[unique_members['Label'] == sel_member_label].iloc[0]
                sel_name = sel_row[col_name]
                sel_phone = sel_row[col_phone]
                
                if pd.isna(sel_phone): mem_records = df_report[df_report[col_name] == sel_name].copy()
                else: mem_records = df_report[(df_report[col_name] == sel_name) & (df_report[col_phone] == sel_phone)].copy()
                mem_records = mem_records.sort_values('Datetime', ascending=False)
                
                st.divider()
                st.subheader(f"ğŸ“„ {sel_name} çš„æ¶ˆè²»ç´€éŒ„")
                
                real_visit_count = mem_records['Date_Parsed'].nunique()
                tx_count = len(mem_records)
                total_spend = mem_records['ç¸½è¨ˆ'].sum()
                avg_spend = total_spend / real_visit_count if real_visit_count > 0 else 0
                
                m1, m2, m3, m4 = st.columns(4)
                m1.metric("ç¸½æ¶ˆè²»", f"${total_spend:,.0f}")
                m2.metric("ä¾†åº—æ¬¡æ•¸ (Days)", f"{real_visit_count} å¤©")
                m3.metric("ç¸½å–®æ•¸ (Txs)", f"{tx_count} å¼µ")
                m4.metric("å¹³å‡å®¢å–® (Per Day)", f"${avg_spend:,.0f}")
                
                st.write("**è©³ç´°äº¤æ˜“åˆ—è¡¨** (é»æ“Šå±•é–‹æ˜ç´°)")
                for i, row in mem_records.iterrows():
                    oid = row.get('Order Number')
                    dt_str = row['Datetime'].strftime('%Y-%m-%d %H:%M')
                    amt = row['ç¸½è¨ˆ']
                    with st.expander(f"{dt_str} - ${amt:.0f} (å–®è™Ÿ: {oid})"):
                         if oid and 'Order Number' in df_details.columns:
                             cols = ['Item Name', 'Item Quantity', 'Item Amount(TWD)']
                             if 'Item Discount' in df_details.columns: cols.append('Item Discount')
                             
                             items = df_details[df_details['Order Number'] == oid][cols]
                             st.dataframe(items, use_container_width=True)
                             st.write(f"ç¸½é …æ•¸: {items['Item Quantity'].sum()}")
                         else: st.write("ç„¡æ˜ç´°è³‡æ–™")

            else: st.warning("æŸ¥ç„¡è³‡æ–™")

    # --- VIEW 4: æ–°èˆŠå®¢åˆ†æ (Guest Analysis) ---
    elif view_mode == "ğŸ†• æ–°èˆŠå®¢åˆ†æ":
        st.title("ğŸ†• æ–°èˆŠå®¢æ¶ˆè²»åˆ†æ")
        
        df_full = df_report_raw 
        col_phone = 'å®¢æˆ¶é›»è©±' if 'å®¢æˆ¶é›»è©±' in df_full.columns else 'Contact'
        
        if col_phone not in df_full.columns:
            st.warning("ç„¡æœƒå“¡é›»è©±æ¬„ä½ï¼Œç„¡æ³•é€²è¡Œåˆ†æ")
        else:
            mask_has_phone = df_full[col_phone].notna() & (df_full[col_phone].astype(str).str.len() > 5)
            df_members_only = df_full[mask_has_phone].copy()
            
            if df_members_only.empty:
                st.warning("ç³»çµ±å…§ç„¡æœ‰æ•ˆçš„æœƒå“¡é›»è©±è³‡æ–™")
            else:
                mem_visits = df_members_only.groupby(col_phone)['Date_Parsed'].nunique()
                
                def get_loyalty(n):
                    if n == 1: return 'New (æ–°å®¢)'
                    if n == 2: return 'Returning (èˆŠå®¢)'
                    return 'Regular (å¸¸å®¢)'
                    
                loyalty_map = mem_visits.apply(get_loyalty).to_dict()
                
                target_df = df_rep.copy()
                target_df['Has_Data'] = target_df[col_phone].notna() & (target_df[col_phone].astype(str).str.len() > 5)
                target_df['Loyalty'] = target_df[col_phone].map(loyalty_map).fillna('Unknown')
                
                # 2. Stats
                st.subheader("1. æœƒå“¡è³‡æ–™è¦†è“‹ç‡ (Data vs No Data)")
                d_gb = target_df.groupby('Has_Data').agg({'ç¸½è¨ˆ': 'sum', 'Date_Parsed': 'count'}).rename(columns={'Date_Parsed': 'Tx_Count'})
                d_gb.index = d_gb.index.map({True: 'æœ‰è³‡æ–™ (Members)', False: 'ç„¡è³‡æ–™ (Guests)'})
                
                c_d1, c_d2 = st.columns(2)
                fig_d1 = px.pie(d_gb, values='Tx_Count', names=d_gb.index, title="äº¤æ˜“ç­†æ•¸åˆ†ä½ˆ")
                fig_d2 = px.pie(d_gb, values='ç¸½è¨ˆ', names=d_gb.index, title="ç‡Ÿæ¥­é¡åˆ†ä½ˆ")
                c_d1.plotly_chart(fig_d1, use_container_width=True)
                c_d2.plotly_chart(fig_d2, use_container_width=True)
                
                st.divider()
                st.subheader("2. æ–°èˆŠå®¢è¶¨å‹¢åˆ†æ (åƒ…å«æœƒå“¡)")
                df_loyal = target_df[target_df['Has_Data']].copy()
                
                if df_loyal.empty:
                    st.warning("å€é–“å…§ç„¡æœƒå“¡è³‡æ–™")
                else:
                    an_int = st.radio("çµ±è¨ˆå–®ä½", ["å¤© (Daily)", "é€± (Weekly)", "4é€± (Monthly)"], horizontal=True, key='an_int')
                    an_freq = 'D'
                    if an_int == "é€± (Weekly)": an_freq = 'W-MON'
                    elif an_int == "4é€± (Monthly)": an_freq = 'M'
                    
                    res_rev = df_loyal.set_index('Date_Parsed').groupby('Loyalty').resample(an_freq)['ç¸½è¨ˆ'].sum().reset_index()
                    fig_l1 = px.bar(res_rev, x='Date_Parsed', y='ç¸½è¨ˆ', color='Loyalty', title=f"å®¢ç¾¤ç‡Ÿæ¥­é¡è²¢ç» ({an_int})", barmode='stack',
                                    category_orders={"Loyalty": ["New (æ–°å®¢)", "Returning (èˆŠå®¢)", "Regular (å¸¸å®¢)"]})
                    st.plotly_chart(fig_l1, use_container_width=True)
                    
                    res_tx = df_loyal.set_index('Date_Parsed').groupby('Loyalty').resample(an_freq).size().reset_index(name='Count')
                    fig_l2 = px.bar(res_tx, x='Date_Parsed', y='Count', color='Loyalty', title=f"å®¢ç¾¤äº¤æ˜“é »æ¬¡ ({an_int})", barmode='stack',
                                    category_orders={"Loyalty": ["New (æ–°å®¢)", "Returning (èˆŠå®¢)", "Regular (å¸¸å®¢)"]})
                    st.plotly_chart(fig_l2, use_container_width=True)


    # --- VIEW 5: æ™ºæ…§é æ¸¬ ---
    elif view_mode == "ğŸ”® æ™ºæ…§é æ¸¬":
        st.title("ğŸ”® AI ç‡Ÿæ”¶é æ¸¬")
        
        days_basis = st.radio("é æ¸¬åŸºç¤", ["éå» 2 é€± (14 Days)", "éå» 4 é€± (28 Days)"], index=0, horizontal=True)
        days_back = 28 if "4" in days_basis else 14
        
        avg_wd, avg_hd = predict_revenue_summary(df_report, days_back=days_back)
        st.subheader(f"ğŸ“Š é æ¸¬åƒæ•¸ ({days_basis} å¹³å‡)")
        c1, c2 = st.columns(2)
        c1.metric("å¹³æ—¥æ—¥å‡ç‡Ÿæ”¶", f"${avg_wd:,.0f}")
        c2.metric("å‡æ—¥æ—¥å‡ç‡Ÿæ”¶", f"${avg_hd:,.0f}")
        
        st.divider()
        st.subheader("ğŸ“… æœªä¾† 12 å€‹æœˆç‡Ÿæ”¶é æ¸¬è¡¨")
        st.caption("å«æœ¬æœˆå·²çŸ¥æ¥­ç¸¾ (Hybrid Forecast)")
        
        forecast_df = predict_monthly_table_hybrid(avg_wd, avg_hd, df_report, months=12)
        
        # P16: Show Weekday/Holiday counts in table
        cols_show = ['Date_Label', 'Weekday Days', 'Holiday Days', 'Forecast Revenue', 'Status']
        st.dataframe(forecast_df[cols_show].style.format({
            'Forecast Revenue': '${:,.0f}',
            'Weekday Days': '{:.0f}',
            'Holiday Days': '{:.0f}'
        }), use_container_width=True)
        
        fig_rev = px.bar(forecast_df, x='Date_Label', y='Forecast Revenue', title="æœªä¾† 12 å€‹æœˆé ä¼°ç‡Ÿæ”¶", color='Status')
        st.plotly_chart(fig_rev, use_container_width=True)

except Exception as e: st.error(f"ç³»çµ±éŒ¯èª¤: {e}")
