import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta, date
from dateutil.relativedelta import relativedelta
import os
import re
import numpy as np

# --- 1. Config ---
st.set_page_config(
    page_title="æ»¾éºµæ™ºæ…§ç‡Ÿé‹å ±è¡¨",
    page_icon="ğŸœ",
    layout="wide"
)

# --- 2. Constants & Loading ---
SHEET_ID = "1hdCvSCZ_4gSSGQxtvW8xCqBNCBAO5H3chCocn2N8qAY"
GID_REPORT = "0"
GID_DETAILS = "1988676024"
LOCAL_DATA_DIR = "/home/eats365/data"

# Taiwan Holidays (2024-2026)
tw_holidays = [
    # 2024
    "2024-01-01", "2024-02-08", "2024-02-09", "2024-02-10", "2024-02-11", "2024-02-12", "2024-02-13", "2024-02-14",
    "2024-02-28", "2024-04-04", "2024-04-05", "2024-05-01", "2024-06-10", "2024-09-17", "2024-10-10", "2024-12-25",
    # 2025
    "2025-01-01", "2025-01-25", "2025-01-26", "2025-01-27", "2025-01-28", "2025-01-29", "2025-01-30", "2025-01-31", 
    "2025-02-01", "2025-02-02", "2025-02-28", "2025-04-03", "2025-04-04", "2025-04-05", "2025-04-06", 
    "2025-05-01", "2025-05-31", "2025-06-01", "2025-06-02", "2025-10-04", "2025-10-05", "2025-10-06", 
    "2025-10-10", "2025-10-11", "2025-10-12", "2025-12-25",
    # 2026
    "2026-01-01", "2026-02-13", "2026-02-14", "2026-02-15", "2026-02-16", "2026-02-17", "2026-02-18",
    "2026-02-28", "2026-04-03", "2026-04-04", "2026-04-05", "2026-04-06", "2026-05-01", "2026-06-19", 
    "2026-09-27", "2026-10-10", "2026-12-25"
]
TW_HOLIDAYS_SET = set(tw_holidays)

@st.cache_data(ttl=300)
def load_data():
    local_report = os.path.join(LOCAL_DATA_DIR, "history_report.csv")
    local_details = os.path.join(LOCAL_DATA_DIR, "history_details.csv")
    
    if os.path.exists(local_report) and os.path.exists(local_details):
        df_report = pd.read_csv(local_report)
        df_details = pd.read_csv(local_details)
    else:
        return pd.DataFrame(), pd.DataFrame()
    return df_report, df_details

def clean_currency(series):
    if series.dtype == 'object':
        return pd.to_numeric(series.astype(str).str.replace(r'[NT\$,]', '', regex=True), errors='coerce').fillna(0)
    return pd.to_numeric(series, errors='coerce').fillna(0)

def preprocess_data(df_report, df_details):
    if df_report.empty or df_details.empty:
        return df_report, df_details

    # --- A. Common Cleaning ---
    if 'ç‹€æ…‹' in df_report.columns:
        # Exclude Cancelled, Closed, AND Void (ä½œå»¢)
        df_report = df_report[~df_report['ç‹€æ…‹'].astype(str).str.contains('å–æ¶ˆ|Cancelled|å·²é—œé–‰|Closed|Void|ä½œå»¢', case=False, na=False)]
    if 'Status' in df_details.columns:
        df_details = df_details[~df_details['Status'].astype(str).str.contains('å–æ¶ˆ|Cancelled|å·²é—œé–‰|Closed|Void|ä½œå»¢', case=False, na=False)]

    if 'date' in df_report.columns:
        df_report['Date_Parsed'] = pd.to_datetime(df_report['date'], errors='coerce')
    if 'date' in df_details.columns:
        df_details['Date_Parsed'] = pd.to_datetime(df_details['date'], errors='coerce')

    # Combine DateTime
    if 'æ™‚é–“' in df_report.columns and 'Date_Parsed' in df_report.columns:
        temp_time = pd.to_datetime(df_report['æ™‚é–“'], errors='coerce')
        time_str = temp_time.dt.strftime('%H:%M:%S').fillna('00:00:00')
        df_report['Datetime'] = pd.to_datetime(
            df_report['Date_Parsed'].dt.strftime('%Y-%m-%d') + ' ' + time_str,
            errors='coerce'
        )

    # Currency
    if 'ç¸½è¨ˆ' in df_report.columns:
        df_report['ç¸½è¨ˆ'] = clean_currency(df_report['ç¸½è¨ˆ'])
    if 'Order Total(TWD)' in df_details.columns:
        df_details['Order Total(TWD)'] = clean_currency(df_details['Order Total(TWD)'])
    if 'Item Amount(TWD)' in df_details.columns:
        df_details['Item Amount(TWD)'] = clean_currency(df_details['Item Amount(TWD)'])
    if 'Item Quantity' in df_details.columns:
        df_details['Item Quantity'] = pd.to_numeric(df_details['Item Quantity'], errors='coerce').fillna(0)

    # --- Deduplicate Modifier Rows ---
    if 'Modifier Name' in df_details.columns:
        df_details = df_details[df_details['Modifier Name'].isna() | (df_details['Modifier Name'] == '')]

    # --- Categorization (Phase 6: Refined) ---
    clean_cols = {c: c.strip() for c in df_details.columns}
    df_details.rename(columns=clean_cols, inplace=True)
    
    def infer_category(row):
        sku = str(row.get('Product SKU', '')).strip().upper()
        name = str(row.get('Item Name', '')).strip()
        
        # 1. Special Cases C-1 (User Request)
        if name in ['è”¥æ²¹é›', 'èŠ­æ¨‚é‡è¦‹äº”èŠ±']:
            return 'C å–®é» (Alacarte)'

        # 2. Priority: Check SKU First Letter
        if len(sku) > 0:
            prefix = sku[0]
            if prefix == 'A': return 'A æ¹¯éºµ (Soup Noodle)'
            if prefix == 'B': return 'B ä¹¾éºµ/é£¯ (Dry/Rice)'
            if prefix == 'C': return 'F å°èœ (Small Sides)' # Phase 6: F is Sides (Wait, User said E=Soup, F=Sides)
            # Let's map strict user request: E->Soup, F->Sides, C->Alacarte?
            # User said: "Eæ‡‰è©²æ˜¯æ¹¯ï¼Œï¼¦æ˜¯å°èœ"
            # But what is A/B/C/D?
            # Assuming A=Soup Noodle, B=Dry/Rice, C=Alacarte, D=Veg?
            # Let's stick to valid mapping:
            
            if prefix == 'E': return 'E æ¹¯å“ (Soup)' # User: E=Soup
            if prefix == 'F': return 'F å°èœ (Small Sides)' # User: F=Sides
            
            # Others:
            if prefix == 'D': return 'C å–®é»/é’èœ (Alacarte/Veg)'
            if prefix == 'S': return 'S å¥—é¤ (Set)'
            
            # If SKU is C, it was Sides before. But User says F is Sides. 
            # If SKU is C, maybe it's Alacarte?
            if prefix == 'C': return 'C å–®é» (Alacarte)'

        # 3. Fallback (Name based)
        item_type = str(row.get('Item Type', ''))
        
        if 'Set Meal' in item_type or 'Combo Item' in item_type:
             if 'Single Item' not in item_type: return 'S å¥—é¤ (Set)'
        
        # Check Name
        if 'æ¹¯éºµ' in name: return 'A æ¹¯éºµ (Soup Noodle)'
        if 'æ‹Œéºµ' in name or 'ä¹¾éºµ' in name or 'é£¯' in name: return 'B ä¹¾éºµ/é£¯ (Dry/Rice)'
        
        if any(x in name for x in ['æ¹¯', 'ç¾¹']): return 'E æ¹¯å“ (Soup)'
        if any(x in name for x in ['è±†å¹²', 'çš®è›‹', 'è±†è…', 'æµ·å¸¶', 'èŠ±ç”Ÿ', 'æ¯›è±†', 'é»ƒç“œ', 'è›‹']): return 'F å°èœ (Small Sides)'
        
        return 'G å…¶ä»– (Others)'
        
    df_details['Category'] = df_details.apply(infer_category, axis=1)

    # --- Day Type ---
    def get_day_type(dt):
        if pd.isnull(dt): return 'Unknown'
        d_str = dt.strftime('%Y-%m-%d')
        if d_str in TW_HOLIDAYS_SET: return 'ç‰¹åˆ¥å‡æ—¥ (Holiday)'
        if dt.weekday() >= 5: return 'é€±æœ« (Weekend)'
        return 'å¹³æ—¥ (Weekday)'
    df_report['Day_Type'] = df_report['Date_Parsed'].apply(get_day_type)
    
    # --- Period ---
    def get_period(dt):
        if pd.isnull(dt): return 'Unknown'
        return 'ä¸­åˆ (Lunch)' if dt.hour < 16 else 'æ™šä¸Š (Dinner)'
    df_report['Period'] = df_report['Datetime'].apply(get_period) if 'Datetime' in df_report.columns else 'Unknown'

    # --- Main Dish Logic ---
    df_details['Is_Main_Dish'] = False
    mask_name = df_details['Item Name'].astype(str).str.contains('éºµ|é£¯', regex=True, na=False)
    mask_exclude_wrapper = pd.Series([True] * len(df_details))
    if 'Item Type' in df_details.columns:
        mask_is_wrapper = df_details['Item Type'].astype(str).str.fullmatch('Combo Item', case=False, na=False)
        mask_exclude_wrapper = ~mask_is_wrapper
    df_details.loc[mask_name & mask_exclude_wrapper, 'Is_Main_Dish'] = True

    return df_report, df_details

def calculate_delta(current, previous):
    if previous == 0: return None
    return (current - previous) / previous

# --- 3. Main App ---
try:
    with st.spinner('æ•¸æ“šè™•ç†ä¸­...'):
        df_report_raw, df_details_raw = load_data()
        df_report, df_details = preprocess_data(df_report_raw, df_details_raw)

    if df_report.empty:
        st.warning("å°šæœªè¼‰å…¥è³‡æ–™")
        st.stop()

    st.sidebar.title("ğŸœ æ»¾éºµ Dashboard")
    view_mode = st.sidebar.radio("åŠŸèƒ½åˆ‡æ›", ["ğŸ“Š ç‡Ÿé‹ç¸½è¦½", "ğŸŸ å•†å“åˆ†æ", "ğŸ‘¥ æœƒå“¡æŸ¥è©¢", "ğŸ”® æ™ºæ…§é æ¸¬"])
    st.sidebar.divider()

    # --- Date Filters ---
    st.sidebar.header("ğŸ“… æ—¥æœŸç¯©é¸")
    today = date.today()
    month_options = [ (today - relativedelta(months=i)).strftime("%Y-%m") for i in range(6) ]
    filter_opts = ["ä»Šæ—¥ (Today)", "æ˜¨æ—¥ (Yesterday)", "æœ¬é€± (This Week)", "æœ¬æœˆ (This Month)", 
                   "è¿‘ 28 å¤©", "è¿‘ 30 å¤©", "è‡ªè¨‚ç¯„åœ"] + month_options
    filter_mode = st.sidebar.selectbox("å¿«é€Ÿå€é–“", filter_opts, index=3)

    start_date, end_date = today, today 
    if filter_mode == "ä»Šæ—¥ (Today)": start_date = end_date = pd.Timestamp(today)
    elif filter_mode == "æ˜¨æ—¥ (Yesterday)": start_date = end_date = pd.Timestamp(today - timedelta(days=1))
    elif filter_mode == "æœ¬é€± (This Week)": start_date = pd.Timestamp(today - timedelta(days=today.weekday())); end_date = pd.Timestamp(today)
    elif filter_mode == "æœ¬æœˆ (This Month)": start_date = pd.Timestamp(today.replace(day=1)); end_date = pd.Timestamp(today)
    elif filter_mode == "è¿‘ 28 å¤©": start_date = pd.Timestamp(today - timedelta(days=28)); end_date = pd.Timestamp(today)
    elif filter_mode == "è¿‘ 30 å¤©": start_date = pd.Timestamp(today - timedelta(days=30)); end_date = pd.Timestamp(today)
    elif filter_mode in month_options: y, m = map(int, filter_mode.split('-')); start_date = pd.Timestamp(date(y, m, 1)); end_date = pd.Timestamp(start_date + relativedelta(months=1, days=-1))
    else: d = st.sidebar.date_input("é¸æ“‡æ—¥æœŸ", [today - timedelta(days=7), today]); start_date = pd.to_datetime(d[0]) if len(d) > 0 else pd.Timestamp(today); end_date = pd.to_datetime(d[1]) if len(d) > 1 else start_date

    # Prev Period
    duration = end_date - start_date
    prev_end = start_date - timedelta(days=1)
    prev_start = prev_end - duration
    
    # Filter
    mask_rep = (df_report['Date_Parsed'] >= start_date) & (df_report['Date_Parsed'] <= end_date)
    df_rep = df_report.loc[mask_rep].copy()
    mask_det = (df_details['Date_Parsed'] >= start_date) & (df_details['Date_Parsed'] <= end_date)
    df_det = df_details.loc[mask_det].copy()
    mask_rep_prev = (df_report['Date_Parsed'] >= prev_start) & (df_report['Date_Parsed'] <= prev_end)
    df_rep_prev = df_report.loc[mask_rep_prev]
    mask_det_prev = (df_details['Date_Parsed'] >= prev_start) & (df_details['Date_Parsed'] <= prev_end)
    df_det_prev = df_details.loc[mask_det_prev]

    # --- VIEW 1: ç‡Ÿé‹ç¸½è¦½ ---
    if view_mode == "ğŸ“Š ç‡Ÿé‹ç¸½è¦½":
        st.title(f"ğŸ“Š ç‡Ÿé‹ç¸½è¦½ ({start_date.date()} ~ {end_date.date()})")
        
        # Metrics
        curr_rev = df_rep['ç¸½è¨ˆ'].sum()
        prev_rev = df_rep_prev['ç¸½è¨ˆ'].sum()
        curr_vis = df_det[df_det['Is_Main_Dish']]['Item Quantity'].sum()
        prev_vis = df_det_prev[df_det_prev['Is_Main_Dish']]['Item Quantity'].sum()
        curr_txs = len(df_rep)
        prev_txs = len(df_rep_prev)
        curr_avg = curr_rev / curr_vis if curr_vis > 0 else 0
        prev_avg = prev_rev / prev_vis if prev_vis > 0 else 0

        c1, c2, c3, c4 = st.columns(4)
        c1.metric("ğŸ’°ç¸½ç‡Ÿæ¥­é¡", f"${curr_rev:,.0f}", f"{calculate_delta(curr_rev, prev_rev):.1%}" if prev_rev else None)
        c2.metric("ğŸœä¾†å®¢æ•¸", f"{curr_vis:,.0f}", f"{calculate_delta(curr_vis, prev_vis):.1%}" if prev_vis else None)
        c3.metric("ğŸ§¾è¨‚å–®æ•¸", f"{curr_txs:,.0f}", f"{calculate_delta(curr_txs, prev_txs):.1%}" if prev_txs else None)
        c4.metric("ğŸ‘¤å¹³å‡å®¢å–®åƒ¹", f"${curr_avg:,.0f}", f"{calculate_delta(curr_avg, prev_avg):.1%}" if prev_avg else None)
        st.divider()

        # Graphs: Revenue (Top)
        col_L, col_R = st.columns([2, 1])
        with col_L:
            st.subheader("ğŸ“ˆ ç‡Ÿæ¥­é¡è¶¨å‹¢ (æ™‚æ®µ)")
            if not df_rep.empty:
                daily_period = df_rep.groupby(['Date_Parsed', 'Period'])['ç¸½è¨ˆ'].sum().reset_index()
                daily_total = df_rep.groupby('Date_Parsed')['ç¸½è¨ˆ'].sum().reset_index().rename(columns={'ç¸½è¨ˆ': 'Daily_Total'})
                daily_period = pd.merge(daily_period, daily_total, on='Date_Parsed', how='left')
                fig = px.bar(
                    daily_period, x='Date_Parsed', y='ç¸½è¨ˆ', color='Period', 
                    barmode='stack', color_discrete_map={'ä¸­åˆ (Lunch)': '#FFC107', 'æ™šä¸Š (Dinner)': '#3F51B5'},
                    custom_data=['Daily_Total']
                )
                fig.update_traces(hovertemplate="Date: %{x}<br>Rev: $%{y:,.0f}<br>Total: $%{customdata[0]:,.0f}")
                st.plotly_chart(fig, use_container_width=True)
        
        with col_R:
            st.subheader("ğŸ“… å¹³å‡æ—¥å¹³å‡ (vs ä¸ŠæœŸ)")
            if not df_rep.empty:
                daily_rev = df_rep.groupby(['Date_Parsed', 'Day_Type'])['ç¸½è¨ˆ'].sum().reset_index()
                curr_type_avg = daily_rev.groupby('Day_Type')['ç¸½è¨ˆ'].mean()
                daily_rev_prev = df_rep_prev.groupby(['Date_Parsed', 'Day_Type'])['ç¸½è¨ˆ'].sum().reset_index() if not df_rep_prev.empty else pd.DataFrame()
                prev_type_avg = daily_rev_prev.groupby('Day_Type')['ç¸½è¨ˆ'].mean() if not daily_rev_prev.empty else pd.Series()
                
                for dtype in ['å¹³æ—¥ (Weekday)', 'é€±æœ« (Weekend)', 'ç‰¹åˆ¥å‡æ—¥ (Holiday)']:
                    val = curr_type_avg.get(dtype, 0)
                    pval = prev_type_avg.get(dtype, 0)
                    st.metric(f"å¹³å‡ {dtype}", f"${val:,.0f}", f"{calculate_delta(val, pval):.1%}" if pval else None)
            st.write("---")
            st.subheader("ğŸ“Œ ç‰¹åˆ¥å‡æ—¥")
            special = df_rep[df_rep['Day_Type'] == 'ç‰¹åˆ¥å‡æ—¥ (Holiday)']['Date_Parsed'].dt.date.unique()
            if len(special) > 0:
                for d in sorted(special): st.write(f"- {d}")

        st.divider()
        st.subheader("ğŸ›µ æ¯æ—¥ç‡Ÿæ”¶çµæ§‹")
        col_type = 'å–®é¡å‹' if 'å–®é¡å‹' in df_rep.columns else 'Order Type'
        if col_type in df_rep.columns:
            daily_type = df_rep.groupby(['Date_Parsed', col_type])['ç¸½è¨ˆ'].sum().reset_index()
            fig_type = px.bar(daily_type, x='Date_Parsed', y='ç¸½è¨ˆ', color=col_type, barmode='stack')
            st.plotly_chart(fig_type, use_container_width=True)

        st.divider()
        
        # Graphs: Visitor & ATV (Bottom)
        c_vis, c_atv = st.columns(2)
        with c_vis:
            st.subheader("ğŸ‘¥ ä¾†å®¢æ•¸è¶¨å‹¢")
            if not df_rep.empty:
                daily_vis = df_det[df_det['Is_Main_Dish']].groupby('Date_Parsed')['Item Quantity'].sum().reset_index()
                fig_v = px.line(daily_vis, x='Date_Parsed', y='Item Quantity', markers=True)
                st.plotly_chart(fig_v, use_container_width=True)
        
        with c_atv:
            st.subheader("ğŸ’° å®¢å–®åƒ¹è¶¨å‹¢")
            if not df_rep.empty and not daily_vis.empty:
                daily_rev_chart = df_rep.groupby('Date_Parsed')['ç¸½è¨ˆ'].sum().reset_index()
                daily_atv = pd.merge(daily_rev_chart, daily_vis, on='Date_Parsed', how='inner')
                daily_atv['ATV'] = daily_atv['ç¸½è¨ˆ'] / daily_atv['Item Quantity']
                fig_a = px.line(daily_atv, x='Date_Parsed', y='ATV', markers=True)
                st.plotly_chart(fig_a, use_container_width=True)
        
        st.divider()
        st.subheader("ğŸ“‹ åŸå§‹å ±è¡¨æ•¸æ“š")
        st.dataframe(df_rep, use_container_width=True)

    # --- VIEW 2: å•†å“åˆ†æ ---
    elif view_mode == "ğŸŸ å•†å“åˆ†æ":
        st.title("ğŸŸ å•†å“éŠ·å”®åˆ†æ")
        
        if 'Item Name' in df_det.columns:
            df_items = df_det.dropna(subset=['Item Name'])
            
            curr_qty = df_items['Item Quantity'].sum()
            prev_qty = df_det_prev['Item Quantity'].sum() if not df_det_prev.empty else 0
            
            st.metric("ç¸½éŠ·å”®æ•¸é‡", f"{curr_qty:,.0f}", f"{calculate_delta(curr_qty, prev_qty):.1%}" if prev_qty else None)
            
            st.divider()
            
            # 1. Detail Analysis flow
            st.subheader("ğŸ“ˆ é¡åˆ¥èˆ‡å•†å“èµ°å‹¢")
            cats = sorted(list(df_items['Category'].unique()))
            sel_cat = st.selectbox("è«‹å…ˆé¸æ“‡é¡åˆ¥ (æŸ¥çœ‹ç´°é …)", cats, index=0)
            
            # Interval Selector (User Req)
            interval = st.radio("èµ°å‹¢å–®ä½", ["å¤© (Daily)", "é€± (Weekly)", "4é€± (Monthly)"], index=0, horizontal=True)
            interval_map = {"å¤© (Daily)": "D", "é€± (Weekly)": "W-MON", "4é€± (Monthly)": "4W-MON"}
            freq = interval_map[interval]

            # Filter by Category
            cat_df = df_items[df_items['Category'] == sel_cat].copy()
            
            # Trend Chart (Left: Chart, Right: Table was old. User wants Rank BELOW Chart)
            
            # Trend Data
            cat_df['PeriodData'] = cat_df['Date_Parsed'].dt.to_period(freq[0] if freq != "4W-MON" else "M") # Simple approx
            # Better resampling
            trend_df = cat_df.set_index('Date_Parsed')
            
            # Select Top Items for Visual Complexity
            top_items = cat_df.groupby('Item Name')['Item Quantity'].sum().nlargest(5).index.tolist()
            sel_items = st.multiselect("é¸æ“‡å•†å“ç¹ªåœ–", cat_df['Item Name'].unique(), default=top_items)
            
            if sel_items:
                # Resample logic
                chart_data = cat_df[cat_df['Item Name'].isin(sel_items)].copy()
                chart_data = chart_data.set_index('Date_Parsed').groupby('Item Name').resample(freq)['Item Quantity'].sum().reset_index()
                
                # Plot
                fig_trend = px.line(chart_data, x='Date_Parsed', y='Item Quantity', color='Item Name', markers=True, 
                                    title=f"{sel_cat} å•†å“éŠ·å”®èµ°å‹¢ ({interval})")
                st.plotly_chart(fig_trend, use_container_width=True)

            # Ranking Table (Below Chart)
            st.divider()
            st.subheader(f"ğŸ“Š {sel_cat} - å•†å“éŠ·å”®ä½”æ¯”")
            
            cat_total_qty = cat_df['Item Quantity'].sum()
            
            c_pie, c_rank = st.columns([1, 1])
            
            with c_pie:
                # Share Pie Chart
                item_pie = cat_df.groupby('Item Name')['Item Quantity'].sum().reset_index()
                fig_pie = px.pie(item_pie, values='Item Quantity', names='Item Name', title=f"{sel_cat} éŠ·é‡ä½”æ¯”")
                st.plotly_chart(fig_pie, use_container_width=True)

            with c_rank:
                 cat_total_rev = cat_df['Item Amount(TWD)'].sum()
                 summary = cat_df.groupby('Item Name').agg({
                    'Item Quantity': 'sum', 
                    'Item Amount(TWD)': 'sum'
                 }).reset_index().sort_values('Item Quantity', ascending=False)
                 
                 summary['Rev %'] = (summary['Item Amount(TWD)'] / cat_total_rev * 100).map('{:.1f}%'.format)
                 summary['Qty %'] = (summary['Item Quantity'] / cat_total_qty * 100).map('{:.1f}%'.format)
                 
                 st.write(f"**{sel_cat} éŠ·å”®æ’è¡Œ**")
                 st.dataframe(summary[['Item Name', 'Item Quantity', 'Item Amount(TWD)', 'Qty %', 'Rev %']], use_container_width=True)

            st.divider()
            st.subheader("ğŸ“‹ åŸå§‹å•†å“æ•¸æ“š (æ¯æ—¥æ•¸é‡)")
            # Pivot table: Date x Item match
            raw_pivot = df_items.groupby(['Date_Parsed', 'Item Name'])['Item Quantity'].sum().reset_index()
            raw_pivot['Date'] = raw_pivot['Date_Parsed'].dt.date
            raw_wide = raw_pivot.pivot(index='Date', columns='Item Name', values='Item Quantity').fillna(0)
            st.dataframe(raw_wide, use_container_width=True)

    # --- VIEW 3: æœƒå“¡æŸ¥è©¢ ---
    elif view_mode == "ğŸ‘¥ æœƒå“¡æŸ¥è©¢":
        st.title("ğŸ‘¥ æœƒå“¡æ¶ˆè²»ç´€éŒ„æŸ¥è©¢")
        
        col_L, col_R = st.columns([1, 2])
        with col_L:
            phone_query = st.text_input("è¼¸å…¥é›»è©±æˆ–å§“å:")
            use_date = st.checkbox("é™åˆ¶æ—¥æœŸç¯„åœ", value=False)
            q_start, q_end = today, today
            
        col_phone = 'å®¢æˆ¶é›»è©±' if 'å®¢æˆ¶é›»è©±' in df_report.columns else 'Contact'
        col_name = 'å®¢æˆ¶å§“å' if 'å®¢æˆ¶å§“å' in df_report.columns else 'Customer Name'

        if phone_query:
            try:
                # Robust Clean
                query_str = str(phone_query).strip()
                query_clean = re.sub(r'\D', '', query_str)
                mask = pd.Series([False]*len(df_report))
                
                if col_phone in df_report.columns and query_clean: 
                    phone_col_clean = df_report[col_phone].astype(str).str.replace(r'\D', '', regex=True)
                    mask |= phone_col_clean.str.contains(query_clean, na=False)
                
                if col_name in df_report.columns: 
                    mask |= df_report[col_name].astype(str).str.contains(query_str, na=False)
                
                member_data = df_report[mask].copy()
                
                if not member_data.empty:
                    name_disp = member_data[col_name].iloc[0] if col_name in member_data.columns else "Unknown"
                    phone_disp = member_data[col_phone].iloc[0] if col_phone in member_data.columns else "Unknown"
                    st.success(f"æœƒå“¡: {name_disp} / é›»è©±: {phone_disp}")
                    c1, c2 = st.columns(2)
                    c1.metric("ç´¯ç©æ¶ˆè²»é‡‘é¡", f"${member_data['ç¸½è¨ˆ'].sum():,.0f}")
                    c2.metric("ç´¯ç©ä¾†åº—æ¬¡æ•¸", f"{len(member_data)} æ¬¡")
                    
                    st.subheader("Hamburger æ­·å²è³¼è²·å“é …")
                    if 'Order Number' in member_data.columns and 'Order Number' in df_details.columns:
                        target_orders = member_data['Order Number'].unique()
                        m_details = df_details[df_details['Order Number'].isin(target_orders)]
                        if not m_details.empty:
                            item_hist = m_details.groupby('Item Name')['Item Quantity'].sum().reset_index().sort_values('Item Quantity', ascending=False)
                            st.dataframe(item_hist, use_container_width=True)
                    st.dataframe(member_data[['date', 'æ™‚é–“', 'ç¸½è¨ˆ']], use_container_width=True)
                else: st.warning("æŸ¥ç„¡ç¬¦åˆè³‡æ–™")
            except Exception as e:
                st.error(f"æŸ¥è©¢ç™¼ç”ŸéŒ¯èª¤: {e}")

    # --- VIEW 4: æ™ºæ…§é æ¸¬ ---
    elif view_mode == "ğŸ”® æ™ºæ…§é æ¸¬":
        st.title("ğŸ”® AI ç‡Ÿæ”¶èˆ‡éŠ·é‡é æ¸¬")
        st.info("æ­¤åŠŸèƒ½ä½¿ç”¨ç°¡å–®ç§»å‹•å¹³å‡ (SMA) é€²è¡Œè¶¨å‹¢é ä¼°ï¼Œåƒ…ä¾›åƒè€ƒã€‚")

        if df_rep.empty:
            st.warning("ç„¡è¶³å¤ æ•¸æ“šé€²è¡Œé æ¸¬")
        else:
            # 1. Revenue Forecast
            st.subheader("ğŸ“ˆ æœªä¾† 7 å¤©ç‡Ÿæ”¶é ä¼°")
            daily_rev = df_report.groupby('Date_Parsed')['ç¸½è¨ˆ'].sum().reset_index()
            daily_rev = daily_rev.sort_values('Date_Parsed')
            
            if len(daily_rev) > 7:
                daily_rev['MA_7'] = daily_rev['ç¸½è¨ˆ'].rolling(window=7).mean()
                last_ma = daily_rev['MA_7'].iloc[-1]
                
                # Generate Future Dates
                last_date = daily_rev['Date_Parsed'].max()
                future_dates = [last_date + timedelta(days=i) for i in range(1, 8)]
                future_rev = [last_ma] * 7 # Simple persistence forecast
                
                future_df = pd.DataFrame({'Date_Parsed': future_dates, 'Forecast': future_rev})
                
                fig_f = px.line(daily_rev, x='Date_Parsed', y='ç¸½è¨ˆ', title="æ­·å²ç‡Ÿæ”¶ vs é æ¸¬è¶¨å‹¢")
                fig_f.add_scatter(x=future_df['Date_Parsed'], y=future_df['Forecast'], mode='lines+markers', name='é æ¸¬ (Forecast)', line=dict(dash='dash', color='red'))
                st.plotly_chart(fig_f, use_container_width=True)
            else:
                st.warning("æ•¸æ“šä¸è¶³ 7 å¤©ï¼Œç„¡æ³•ç”¢ç”Ÿè¶¨å‹¢")

            st.divider()
            
            # 2. Item Forecast
            st.subheader("ğŸŸ ç†±éŠ·å•†å“éŠ·é‡é ä¼°")
            if 'Item Name' in df_details.columns:
                top_items = df_details.groupby('Item Name')['Item Quantity'].sum().nlargest(5).index
                sel_item = st.selectbox("é¸æ“‡å•†å“", top_items)
                
                item_daily = df_details[df_details['Item Name'] == sel_item].groupby('Date_Parsed')['Item Quantity'].sum().reset_index()
                if len(item_daily) > 7:
                    item_daily['MA_7'] = item_daily['Item Quantity'].rolling(window=7).mean()
                    last_val = item_daily['MA_7'].iloc[-1]
                    st.metric(f"{sel_item} - é ä¼°æ—¥éŠ·é‡", f"{last_val:.1f} ä»½")
                    st.line_chart(item_daily.set_index('Date_Parsed')['Item Quantity'])
                else:
                    st.warning("è©²å•†å“æ•¸æ“šä¸è¶³")

except Exception as e: st.error(f"ç³»çµ±éŒ¯èª¤: {e}")
