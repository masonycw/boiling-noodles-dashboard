import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta, date
from dateutil.relativedelta import relativedelta
import os
import re
import numpy as np

# --- 1. Config ---
st.set_page_config(
    page_title="æ»¾éºµæ™ºæ…§ç‡Ÿé‹å ±è¡¨",
    page_icon="ğŸœ",
    layout="wide"
)

# --- 2. Constants & Loading ---
LOCAL_DATA_DIR = "/home/eats365/data"

# Taiwan Holidays (2024-2026)
tw_holidays = [
    # 2024
    "2024-01-01", "2024-02-08", "2024-02-09", "2024-02-10", "2024-02-11", "2024-02-12", "2024-02-13", "2024-02-14",
    "2024-02-28", "2024-04-04", "2024-04-05", "2024-05-01", "2024-06-10", "2024-09-17", "2024-10-10", "2024-12-25",
    # 2025
    "2025-01-01", "2025-01-25", "2025-01-26", "2025-01-27", "2025-01-28", "2025-01-29", "2025-01-30", "2025-01-31", 
    "2025-02-01", "2025-02-02", "2025-02-28", "2025-04-03", "2025-04-04", "2025-04-05", "2025-04-06", 
    "2025-05-01", "2025-05-31", "2025-06-01", "2025-06-02", "2025-10-04", "2025-10-05", "2025-10-06", 
    "2025-10-10", "2025-10-11", "2025-10-12", "2025-12-25",
    # 2026
    "2026-01-01", "2026-02-13", "2026-02-14", "2026-02-15", "2026-02-16", "2026-02-17", "2026-02-18",
    "2026-02-28", "2026-04-03", "2026-04-04", "2026-04-05", "2026-04-06", "2026-05-01", "2026-06-19", 
    "2026-09-27", "2026-10-10", "2026-12-25"
]
TW_HOLIDAYS_SET = set(tw_holidays)

@st.cache_data(ttl=300)
def load_data():
    local_report = os.path.join(LOCAL_DATA_DIR, "history_report.csv")
    local_details = os.path.join(LOCAL_DATA_DIR, "history_details.csv")
    
    if os.path.exists(local_report) and os.path.exists(local_details):
        df_report = pd.read_csv(local_report)
        df_details = pd.read_csv(local_details)
    else:
        return pd.DataFrame(), pd.DataFrame()
    return df_report, df_details

def clean_currency(series):
    if series.dtype == 'object':
        return pd.to_numeric(series.astype(str).str.replace(r'[NT\$,]', '', regex=True), errors='coerce').fillna(0)
    return pd.to_numeric(series, errors='coerce').fillna(0)

def preprocess_data(df_report, df_details):
    if df_report.empty or df_details.empty:
        return df_report, df_details

    # --- A. Common Cleaning ---
    if 'ç‹€æ…‹' in df_report.columns:
        df_report = df_report[~df_report['ç‹€æ…‹'].astype(str).str.contains('å–æ¶ˆ|Cancelled|å·²é—œé–‰|Closed|Void|ä½œå»¢', case=False, na=False)]
    if 'Status' in df_details.columns:
        df_details = df_details[~df_details['Status'].astype(str).str.contains('å–æ¶ˆ|Cancelled|å·²é—œé–‰|Closed|Void|ä½œå»¢', case=False, na=False)]

    if 'date' in df_report.columns:
        df_report['Date_Parsed'] = pd.to_datetime(df_report['date'], errors='coerce')
    if 'date' in df_details.columns:
        df_details['Date_Parsed'] = pd.to_datetime(df_details['date'], errors='coerce')

    # Combine DateTime
    if 'æ™‚é–“' in df_report.columns and 'Date_Parsed' in df_report.columns:
        temp_time = pd.to_datetime(df_report['æ™‚é–“'], errors='coerce')
        time_str = temp_time.dt.strftime('%H:%M:%S').fillna('00:00:00')
        df_report['Datetime'] = pd.to_datetime(
            df_report['Date_Parsed'].dt.strftime('%Y-%m-%d') + ' ' + time_str,
            errors='coerce'
        )

    # Currency
    if 'ç¸½è¨ˆ' in df_report.columns:
        df_report['ç¸½è¨ˆ'] = clean_currency(df_report['ç¸½è¨ˆ'])
    if 'Order Total(TWD)' in df_details.columns:
        df_details['Order Total(TWD)'] = clean_currency(df_details['Order Total(TWD)'])
    if 'Item Amount(TWD)' in df_details.columns:
        df_details['Item Amount(TWD)'] = clean_currency(df_details['Item Amount(TWD)'])
    if 'Item Quantity' in df_details.columns:
        df_details['Item Quantity'] = pd.to_numeric(df_details['Item Quantity'], errors='coerce').fillna(0)

    # --- Deduplicate Modifier Rows ---
    if 'Modifier Name' in df_details.columns:
        df_details = df_details[df_details['Modifier Name'].isna() | (df_details['Modifier Name'] == '')]

    # --- Feature: Aggregate "Super Value Combos" ---
    if 'Item Name' in df_details.columns:
        mask_combo = df_details['Item Name'].astype(str).str.contains('è¶…å€¼çµ„åˆ', na=False)
        df_details.loc[mask_combo, 'Item Name'] = 'è¶…å€¼çµ„åˆ'
    
    # --- Categorization (Phase 11 Update) ---
    clean_cols = {c: c.strip() for c in df_details.columns}
    df_details.rename(columns=clean_cols, inplace=True)
    
    def infer_category(row):
        sku = str(row.get('Product SKU', '')).strip().upper()
        name = str(row.get('Item Name', '')).strip()
        
        # 1. Special Cases C-1
        if name in ['è”¥æ²¹é›', 'èŠ­æ¨‚é‡è¦‹äº”èŠ±']: return 'C-1 ç‰¹æ®Šå–®é» (Special)'
        if name == 'è¶…å€¼çµ„åˆ': return 'S å¥—é¤ (Set)'

        # 2. Priority: Check SKU First Letter
        if len(sku) > 0:
            prefix = sku[0]
            if prefix == 'A': return 'A æ¹¯éºµ (Soup Noodle)'
            if prefix == 'B': return 'B ä¹¾éºµ/é£¯ (Dry/Rice)'
            if prefix == 'E': return 'E æ¹¯å“ (Soup)' 
            
            # User Req #5 (P11): "Small dishes change to D, Veg change to C, F is Drinks"
            if prefix == 'C': return 'C é’èœ (Vegetables)' 
            if prefix == 'D': return 'D å°èœ (Sides)' 
            if prefix == 'F': return 'F é£²æ–™ (Drinks)'
            
            if prefix == 'S': return 'S å¥—é¤ (Set)'

        # 3. Fallback (Name based)
        item_type = str(row.get('Item Type', ''))
        if 'Set Meal' in item_type or 'Combo Item' in item_type:
             if 'Single Item' not in item_type: return 'S å¥—é¤ (Set)'
        
        if 'æ¹¯éºµ' in name: return 'A æ¹¯éºµ (Soup Noodle)'
        if 'æ‹Œéºµ' in name or 'ä¹¾éºµ' in name or 'é£¯' in name: return 'B ä¹¾éºµ/é£¯ (Dry/Rice)'
        
        if any(x in name for x in ['æ¹¯', 'ç¾¹']): return 'E æ¹¯å“ (Soup)'
        # Swap logic consistent with SKU
        if any(x in name for x in ['èœ', 'æ°´è“®']): return 'C é’èœ (Vegetables)'
        if any(x in name for x in ['è±†å¹²', 'çš®è›‹', 'è±†è…', 'æµ·å¸¶', 'èŠ±ç”Ÿ', 'æ¯›è±†', 'é»ƒç“œ', 'è›‹']): return 'D å°èœ (Sides)'
        if any(x in name for x in ['èŒ¶', 'é£²', 'å¯æ¨‚', 'é›ªç¢§']): return 'F é£²æ–™ (Drinks)'
        
        return 'G å…¶ä»– (Others)'
        
    df_details['Category'] = df_details.apply(infer_category, axis=1)

    # --- Day Type ---
    def get_day_type(dt):
        if pd.isnull(dt): return 'Unknown'
        d_str = dt.strftime('%Y-%m-%d')
        if d_str in TW_HOLIDAYS_SET: return 'å‡æ—¥ (Holiday)' 
        if dt.weekday() >= 5: return 'å‡æ—¥ (Holiday)' 
        return 'å¹³æ—¥ (Weekday)'
    df_report['Day_Type'] = df_report['Date_Parsed'].apply(get_day_type)
    
    # --- Period ---
    def get_period(dt):
        if pd.isnull(dt): return 'Unknown'
        return 'ä¸­åˆ (Lunch)' if dt.hour < 16 else 'æ™šä¸Š (Dinner)'
    df_report['Period'] = df_report['Datetime'].apply(get_period) if 'Datetime' in df_report.columns else 'Unknown'

    # --- Main Dish Logic ---
    df_details['Is_Main_Dish'] = False
    mask_name = df_details['Item Name'].astype(str).str.contains('éºµ|é£¯', regex=True, na=False)
    mask_exclude_wrapper = pd.Series([True] * len(df_details))
    if 'Item Type' in df_details.columns:
        mask_is_wrapper = df_details['Item Type'].astype(str).str.fullmatch('Combo Item', case=False, na=False)
        mask_exclude_wrapper = ~mask_is_wrapper
    df_details.loc[mask_name & mask_exclude_wrapper, 'Is_Main_Dish'] = True

    return df_report, df_details

def calculate_delta(current, previous):
    if previous == 0: return None
    return (current - previous) / previous

# --- Prediction Logic P11 ---
def predict_revenue_summary(df_report):
    # Base: Last 2 Weeks
    end_date = df_report['Date_Parsed'].max()
    start_date = end_date - timedelta(days=14)
    mask = (df_report['Date_Parsed'] >= start_date) & (df_report['Date_Parsed'] <= end_date)
    recent = df_report[mask].copy()

    def get_simple_type(dt):
        d_str = dt.strftime('%Y-%m-%d')
        if d_str in TW_HOLIDAYS_SET or dt.weekday() >= 5: return 'Holiday'
        return 'Weekday'
    recent['Simple'] = recent['Date_Parsed'].apply(get_simple_type)
    
    avgs = recent.groupby('Simple')['ç¸½è¨ˆ'].mean()
    avg_wd = avgs.get('Weekday', 0)
    avg_hd = avgs.get('Holiday', 0)
    
    # Fallback if missing
    if avg_wd == 0 and avg_hd > 0: avg_wd = avg_hd
    if avg_hd == 0 and avg_wd > 0: avg_hd = avg_wd
    
    return avg_wd, avg_hd

def predict_monthly_table(avg_wd, avg_hd, start_date, months=12):
    # Forecast next 12 months
    # Logic: For each month, count weekdays and holidays, multiply by avg
    
    dates = []
    curr = start_date + timedelta(days=1)
    end = start_date + relativedelta(months=months)
    
    while curr < end:
        dates.append(curr)
        curr += timedelta(days=1)
        
    df_future = pd.DataFrame({'Date': dates})
    df_future['Month'] = df_future['Date'].dt.to_period('M')
    
    def get_simple_type(dt):
        d_str = dt.strftime('%Y-%m-%d')
        if d_str in TW_HOLIDAYS_SET or dt.weekday() >= 5: return 'Holiday'
        return 'Weekday'

    df_future['Type'] = df_future['Date'].apply(get_simple_type)
    
    summary = []
    groups = df_future.groupby('Month')
    for m, group in groups:
        n_wd = (group['Type'] == 'Weekday').sum()
        n_hd = (group['Type'] == 'Holiday').sum()
        rev = (n_wd * avg_wd) + (n_hd * avg_hd)
        summary.append({
            'Month': str(m),
            'Weekday Days': n_wd,
            'Holiday Days': n_hd,
            'Forecast Revenue': rev
        })
    return pd.DataFrame(summary)

# --- 3. Main App ---
try:
    with st.spinner('æ•¸æ“šè™•ç†ä¸­...'):
        df_report_raw, df_details_raw = load_data()
        df_report, df_details = preprocess_data(df_report_raw, df_details_raw)

    if df_report.empty:
        st.warning("å°šæœªè¼‰å…¥è³‡æ–™")
        st.stop()

    st.sidebar.title("ğŸœ æ»¾éºµ Dashboard")
    view_mode = st.sidebar.radio("åŠŸèƒ½åˆ‡æ›", ["ğŸ“Š ç‡Ÿé‹ç¸½è¦½", "ğŸŸ å•†å“åˆ†æ", "ğŸ‘¥ æœƒå“¡æŸ¥è©¢", "ğŸ”® æ™ºæ…§é æ¸¬"])
    st.sidebar.divider()

    st.sidebar.header("ğŸ“… æ—¥æœŸç¯©é¸")
    today = date.today()
    month_options = [ (today - relativedelta(months=i)).strftime("%Y-%m") for i in range(6) ]
    # P11: Added Last 2 Months, Last 6 Months
    filter_opts = ["ä»Šæ—¥ (Today)", "æ˜¨æ—¥ (Yesterday)", "æœ¬é€± (This Week)", "æœ¬æœˆ (This Month)", 
                   "è¿‘ 28 å¤©", "è¿‘ 30 å¤©", "è¿‘ 2 å€‹æœˆ (60 Days)", "è¿‘ 6 å€‹æœˆ (180 Days)", "è‡ªè¨‚ç¯„åœ"] + month_options
    filter_mode = st.sidebar.selectbox("å¿«é€Ÿå€é–“", filter_opts, index=3)

    start_date, end_date = today, today 
    if filter_mode == "ä»Šæ—¥ (Today)": start_date = end_date = pd.Timestamp(today)
    elif filter_mode == "æ˜¨æ—¥ (Yesterday)": start_date = end_date = pd.Timestamp(today - timedelta(days=1))
    elif filter_mode == "æœ¬é€± (This Week)": start_date = pd.Timestamp(today - timedelta(days=today.weekday())); end_date = pd.Timestamp(today)
    elif filter_mode == "æœ¬æœˆ (This Month)": start_date = pd.Timestamp(today.replace(day=1)); end_date = pd.Timestamp(today)
    elif filter_mode == "è¿‘ 28 å¤©": start_date = pd.Timestamp(today - timedelta(days=28)); end_date = pd.Timestamp(today)
    elif filter_mode == "è¿‘ 30 å¤©": start_date = pd.Timestamp(today - timedelta(days=30)); end_date = pd.Timestamp(today)
    elif filter_mode == "è¿‘ 2 å€‹æœˆ (60 Days)": start_date = pd.Timestamp(today - timedelta(days=60)); end_date = pd.Timestamp(today)
    elif filter_mode == "è¿‘ 6 å€‹æœˆ (180 Days)": start_date = pd.Timestamp(today - timedelta(days=180)); end_date = pd.Timestamp(today)
    elif filter_mode in month_options: y, m = map(int, filter_mode.split('-')); start_date = pd.Timestamp(date(y, m, 1)); end_date = pd.Timestamp(start_date + relativedelta(months=1, days=-1))
    else: d = st.sidebar.date_input("é¸æ“‡æ—¥æœŸ", [today - timedelta(days=7), today]); start_date = pd.to_datetime(d[0]) if len(d) > 0 else pd.Timestamp(today); end_date = pd.to_datetime(d[1]) if len(d) > 1 else start_date

    mask_rep = (df_report['Date_Parsed'] >= start_date) & (df_report['Date_Parsed'] <= end_date)
    df_rep = df_report.loc[mask_rep].copy()
    mask_det = (df_details['Date_Parsed'] >= start_date) & (df_details['Date_Parsed'] <= end_date)
    df_det = df_details.loc[mask_det].copy()

    prev_end = start_date - timedelta(days=1)
    duration = end_date - start_date
    prev_start = prev_end - duration
    mask_rep_prev = (df_report['Date_Parsed'] >= prev_start) & (df_report['Date_Parsed'] <= prev_end)
    df_rep_prev = df_report.loc[mask_rep_prev].copy()
    mask_det_prev = (df_details['Date_Parsed'] >= prev_start) & (df_details['Date_Parsed'] <= prev_end)
    df_det_prev = df_details.loc[mask_det_prev].copy()

    # --- VIEW 1: ç‡Ÿé‹ç¸½è¦½ ---
    if view_mode == "ğŸ“Š ç‡Ÿé‹ç¸½è¦½":
        st.title(f"ğŸ“Š ç‡Ÿé‹ç¸½è¦½ ({start_date.date()} ~ {end_date.date()})")
        
        curr_rev = df_rep['ç¸½è¨ˆ'].sum()
        prev_rev = df_rep_prev['ç¸½è¨ˆ'].sum()
        curr_vis = df_det[df_det['Is_Main_Dish']]['Item Quantity'].sum()
        prev_vis = df_det_prev[df_det_prev['Is_Main_Dish']]['Item Quantity'].sum()
        curr_txs = len(df_rep)
        prev_txs = len(df_rep_prev)
        curr_avg = curr_rev / curr_vis if curr_vis > 0 else 0
        prev_avg = prev_rev / prev_vis if prev_vis > 0 else 0

        c1, c2, c3, c4 = st.columns(4)
        c1.metric("ğŸ’°ç¸½ç‡Ÿæ¥­é¡", f"${curr_rev:,.0f}", f"{calculate_delta(curr_rev, prev_rev):.1%}" if prev_rev else None)
        c2.metric("ğŸœä¾†å®¢æ•¸", f"{curr_vis:,.0f}", f"{calculate_delta(curr_vis, prev_vis):.1%}" if prev_vis else None)
        c3.metric("ğŸ§¾è¨‚å–®æ•¸", f"{curr_txs:,.0f}", f"{calculate_delta(curr_txs, prev_txs):.1%}" if prev_txs else None)
        c4.metric("ğŸ‘¤å¹³å‡å®¢å–®åƒ¹", f"${curr_avg:,.0f}", f"{calculate_delta(curr_avg, prev_avg):.1%}" if prev_avg else None)
        st.divider()

        # P11: Overview Interval Selector
        ov_int = st.radio("åœ–è¡¨å–®ä½", ["å¤© (Daily)", "é€± (Weekly)", "4é€± (Monthly)"], horizontal=True, key='ov_int')
        ov_freq = 'D'
        if ov_int == "é€± (Weekly)": ov_freq = 'W-MON'
        elif ov_int == "4é€± (Monthly)": ov_freq = 'M'

        col_L, col_R = st.columns([2, 1])
        with col_L:
            st.subheader("ğŸ“ˆ ç‡Ÿæ¥­é¡è¶¨å‹¢ (æ™‚æ®µ)")
            if not df_rep.empty:
                # Group by Period first, then resample
                # This is tricky with Period as a category. Simpler: Pivot -> Resample -> Unstack
                # Or just Daily for bars if user selects Day.
                
                if ov_freq == 'D':
                    daily_period = df_rep.groupby(['Date_Parsed', 'Period'])['ç¸½è¨ˆ'].sum().reset_index()
                    # Add total for custom data
                    daily_total = df_rep.groupby('Date_Parsed')['ç¸½è¨ˆ'].sum().reset_index().rename(columns={'ç¸½è¨ˆ': 'Daily_Total'})
                    daily_period = pd.merge(daily_period, daily_total, on='Date_Parsed', how='left')
                    
                    fig = px.bar(daily_period, x='Date_Parsed', y='ç¸½è¨ˆ', color='Period', barmode='stack', color_discrete_map={'ä¸­åˆ (Lunch)': '#FFC107', 'æ™šä¸Š (Dinner)': '#3F51B5'}, custom_data=['Daily_Total'])
                    fig.update_traces(hovertemplate="Date: %{x}<br>Rev: $%{y:,.0f}<br>Total: $%{customdata[0]:,.0f}")
                else:
                    # For Week/Month, Resample Total
                    resampled = df_rep.set_index('Date_Parsed').resample(ov_freq)['ç¸½è¨ˆ'].sum().reset_index()
                    fig = px.bar(resampled, x='Date_Parsed', y='ç¸½è¨ˆ', title=f"ç‡Ÿæ¥­é¡ ({ov_int})")
                
                st.plotly_chart(fig, use_container_width=True)
        with col_R:
            st.subheader("ğŸ“… å¹³å‡æ—¥å¹³å‡ (vs ä¸ŠæœŸ)")
            if not df_rep.empty:
                daily_rev = df_rep.groupby(['Date_Parsed', 'Day_Type'])['ç¸½è¨ˆ'].sum().reset_index()
                curr_type_avg = daily_rev.groupby('Day_Type')['ç¸½è¨ˆ'].mean()
                daily_rev_prev = df_rep_prev.groupby(['Date_Parsed', 'Day_Type'])['ç¸½è¨ˆ'].sum().reset_index() if not df_rep_prev.empty else pd.DataFrame()
                prev_type_avg = daily_rev_prev.groupby('Day_Type')['ç¸½è¨ˆ'].mean() if not daily_rev_prev.empty else pd.Series()
                for dtype in ['å¹³æ—¥ (Weekday)', 'å‡æ—¥ (Holiday)']:
                    val = curr_type_avg.get(dtype, 0)
                    pval = prev_type_avg.get(dtype, 0)
                    st.metric(f"å¹³å‡ {dtype}", f"${val:,.0f}", f"{calculate_delta(val, pval):.1%}" if pval else None)

        st.divider()
        c_vis, c_atv = st.columns(2)
        with c_vis:
            st.subheader("ğŸ‘¥ ä¾†å®¢æ•¸è¶¨å‹¢")
            if not df_rep.empty:
                # Use ov_freq
                daily_vis = df_det[df_det['Is_Main_Dish']].set_index('Date_Parsed').resample(ov_freq)['Item Quantity'].sum().reset_index()
                fig_v = px.line(daily_vis, x='Date_Parsed', y='Item Quantity', markers=True, title=f"ä¾†å®¢æ•¸ ({ov_int})")
                st.plotly_chart(fig_v, use_container_width=True)
        with c_atv:
            st.subheader("ğŸ’° å®¢å–®åƒ¹è¶¨å‹¢")
            if not df_rep.empty:
                # Calculate ATV per freq
                res_rev = df_rep.set_index('Date_Parsed').resample(ov_freq)['ç¸½è¨ˆ'].sum()
                res_vis = df_det[df_det['Is_Main_Dish']].set_index('Date_Parsed').resample(ov_freq)['Item Quantity'].sum()
                df_atv = pd.DataFrame({'Rev': res_rev, 'Vis': res_vis})
                df_atv['ATV'] = df_atv['Rev'] / df_atv['Vis']
                df_atv = df_atv.reset_index()
                
                fig_a = px.line(df_atv, x='Date_Parsed', y='ATV', markers=True, title=f"å®¢å–®åƒ¹ ({ov_int})")
                st.plotly_chart(fig_a, use_container_width=True)
        
        st.divider()
        st.subheader("ğŸ“‹ æ¯æ—¥ç‡Ÿé‹å ±è¡¨ (Daily Report)")
        if not df_rep.empty:
            base_agg = df_rep.groupby('Date_Parsed')['ç¸½è¨ˆ'].sum().reset_index().rename(columns={'ç¸½è¨ˆ': 'ç¸½ç‡Ÿæ¥­é¡'})
            base_agg['Date'] = base_agg['Date_Parsed'].dt.date
            period_rev = df_rep.groupby(['Date_Parsed', 'Period'])['ç¸½è¨ˆ'].sum().unstack(fill_value=0).reset_index()
            # Handle potential missing columns
            for p in ['ä¸­åˆ (Lunch)', 'æ™šä¸Š (Dinner)']: 
                if p not in period_rev.columns: period_rev[p] = 0
            period_rev.rename(columns={'ä¸­åˆ (Lunch)': 'åˆé¤ç‡Ÿæ”¶', 'æ™šä¸Š (Dinner)': 'æ™šé¤ç‡Ÿæ”¶'}, inplace=True)
            
            vis_agg = df_det[df_det['Is_Main_Dish']].groupby('Date_Parsed')['Item Quantity'].sum().reset_index().rename(columns={'Item Quantity': 'ä¾†å®¢æ•¸'})
            
            col_type = 'å–®é¡å‹' if 'å–®é¡å‹' in df_rep.columns else 'Order Type'
            if col_type in df_rep.columns:
                channel_rev = df_rep.groupby(['Date_Parsed', col_type])['ç¸½è¨ˆ'].sum().unstack(fill_value=0).reset_index()
                rename_map = {}
                for c in channel_rev.columns:
                    if 'Delivery' in str(c) or 'å¤–é€' in str(c): rename_map[c] = 'å¤–é€ç‡Ÿæ”¶'
                    if 'Takeout' in str(c) or 'å¤–å¸¶' in str(c): rename_map[c] = 'å¤–å¸¶ç‡Ÿæ”¶'
                    if 'Dine-in' in str(c) or 'å…§ç”¨' in str(c): rename_map[c] = 'å ‚é£Ÿç‡Ÿæ”¶ (å…§ç”¨)' 
                channel_rev.rename(columns=rename_map, inplace=True)
            else:
                channel_rev = pd.DataFrame(columns=['Date_Parsed'])

            final_df = base_agg.merge(period_rev, on='Date_Parsed', how='left')
            final_df = final_df.merge(vis_agg, on='Date_Parsed', how='left')
            final_df = final_df.merge(channel_rev, on='Date_Parsed', how='left')
            final_df['å®¢å–®åƒ¹'] = (final_df['ç¸½ç‡Ÿæ¥­é¡'] / final_df['ä¾†å®¢æ•¸']).replace([np.inf, -np.inf], 0).fillna(0).round(0)
            
            cols_show = ['Date', 'åˆé¤ç‡Ÿæ”¶', 'æ™šé¤ç‡Ÿæ”¶', 'ç¸½ç‡Ÿæ¥­é¡', 'ä¾†å®¢æ•¸', 'å®¢å–®åƒ¹']
            # Explicit checks
            for c in ['å¤–é€ç‡Ÿæ”¶', 'å¤–å¸¶ç‡Ÿæ”¶', 'å ‚é£Ÿç‡Ÿæ”¶ (å…§ç”¨)']:
                if c in final_df.columns: cols_show.append(c)
                
            st.dataframe(final_df[cols_show].sort_values('Date', ascending=False).style.format({
                'åˆé¤ç‡Ÿæ”¶': '${:,.0f}', 'æ™šé¤ç‡Ÿæ”¶': '${:,.0f}', 'ç¸½ç‡Ÿæ¥­é¡': '${:,.0f}',
                'ä¾†å®¢æ•¸': '{:,.0f}', 'å®¢å–®åƒ¹': '${:,.0f}',
                'å¤–é€ç‡Ÿæ”¶': '${:,.0f}', 'å¤–å¸¶ç‡Ÿæ”¶': '${:,.0f}', 'å ‚é£Ÿç‡Ÿæ”¶ (å…§ç”¨)': '${:,.0f}'
            }), use_container_width=True)

    # --- VIEW 2: å•†å“åˆ†æ ---
    elif view_mode == "ğŸŸ å•†å“åˆ†æ":
        st.title("ğŸŸ å•†å“éŠ·å”®åˆ†æ")
        
        if 'Item Name' in df_det.columns:
            df_items = df_det.dropna(subset=['Item Name'])
            
            st.subheader("ğŸ“ˆ é¡åˆ¥èˆ‡å•†å“èµ°å‹¢")
            
            cats = sorted(list(df_items['Category'].unique()))
            comp_opt = "ğŸ“‹ [ç‰¹æ®Š] ä¹¾éºµ/é£¯ vs æ¹¯éºµ (Dry/Rice vs Soup)"
            cats.insert(0, comp_opt)
            
            sel_cat = st.selectbox("è«‹é¸æ“‡é¡åˆ¥ æˆ– ç‰¹æ®Šæ¯”è¼ƒ", cats, index=0)
            
            interval = st.radio("èµ°å‹¢å–®ä½", ["å¤© (Daily)", "é€± (Weekly)", "4é€± (Monthly)"], index=0, horizontal=True)
            freq_alias = 'D'
            if interval == "é€± (Weekly)": freq_alias = 'W-MON'
            elif interval == "4é€± (Monthly)": freq_alias = 'M' 

            if sel_cat == comp_opt:
                # SPECIAL CHART: Sum of Cat A vs Sum of Cat B
                mask_a = df_items['Category'].str.contains('A æ¹¯éºµ', na=False)
                mask_b = df_items['Category'].str.contains('B ä¹¾éºµ', na=False)
                
                comp_df = df_items[mask_a | mask_b].copy()
                comp_df['Group'] = comp_df['Category'].apply(lambda x: 'æ¹¯éºµ (Soup)' if 'A æ¹¯éºµ' in x else 'ä¹¾éºµ/é£¯ (Dry/Rice)')
                
                chart_data = comp_df.set_index('Date_Parsed').groupby('Group').resample(freq_alias)['Item Quantity'].sum().reset_index()
                
                # Main Chart
                fig_trend = px.line(chart_data, x='Date_Parsed', y='Item Quantity', color='Group', markers=True, title=f"ä¹¾éºµ/é£¯ vs æ¹¯éºµ - {interval} èµ°å‹¢æ¯”è¼ƒ")
                st.plotly_chart(fig_trend, use_container_width=True)
                
                # Ratio Chart (P11)
                st.write("**æ¯”ä¾‹åˆ†æ (Ratio)**")
                pivot_ratio = chart_data.pivot(index='Date_Parsed', columns='Group', values='Item Quantity').fillna(0)
                pivot_ratio['Total'] = pivot_ratio['æ¹¯éºµ (Soup)'] + pivot_ratio['ä¹¾éºµ/é£¯ (Dry/Rice)']
                pivot_ratio['æ¹¯éºµ %'] = pivot_ratio['æ¹¯éºµ (Soup)'] / pivot_ratio['Total']
                pivot_ratio['ä¹¾éºµ/é£¯ %'] = pivot_ratio['ä¹¾éºµ/é£¯ (Dry/Rice)'] / pivot_ratio['Total']
                
                fig_ratio = px.bar(pivot_ratio.reset_index(), x='Date_Parsed', y=['æ¹¯éºµ %', 'ä¹¾éºµ/é£¯ %'], barmode='stack', title="éŠ·å”®æ¯”ä¾‹ (Share %)")
                st.plotly_chart(fig_ratio, use_container_width=True)

            else:
                cat_df = df_items[df_items['Category'] == sel_cat].copy()
                top_items = cat_df.groupby('Item Name')['Item Quantity'].sum().nlargest(5).index.tolist()
                sel_items = st.multiselect("é¸æ“‡å•†å“ç¹ªåœ–", cat_df['Item Name'].unique(), default=top_items)
                
                if sel_items:
                    chart_data = cat_df[cat_df['Item Name'].isin(sel_items)].copy()
                    chart_data = chart_data.set_index('Date_Parsed').groupby('Item Name').resample(freq_alias)['Item Quantity'].sum().reset_index()
                    fig_trend = px.line(chart_data, x='Date_Parsed', y='Item Quantity', color='Item Name', markers=True, title=f"{sel_cat} {interval} èµ°å‹¢")
                    st.plotly_chart(fig_trend, use_container_width=True)

    # --- VIEW 3: æœƒå“¡æŸ¥è©¢ ---
    elif view_mode == "ğŸ‘¥ æœƒå“¡æŸ¥è©¢":
        st.title("ğŸ‘¥ æœƒå“¡æ¶ˆè²»ç´€éŒ„æŸ¥è©¢")
        st.subheader("ğŸ” 1. æœå°‹æœƒå“¡")
        search_term = st.text_input("è¼¸å…¥ å§“å æˆ– é›»è©± (æ¨¡ç³Šæœå°‹)", "")
        
        col_phone = 'å®¢æˆ¶é›»è©±' if 'å®¢æˆ¶é›»è©±' in df_report.columns else 'Contact'
        col_name = 'å®¢æˆ¶å§“å' if 'å®¢æˆ¶å§“å' in df_report.columns else 'Customer Name'
        
        if search_term:
            s_clean = search_term.strip()
            if col_phone in df_report.columns:
                 phone_series = df_report[col_phone].astype(str).str.replace(r'\D', '', regex=True)
            else: phone_series = pd.Series([])
            if col_name in df_report.columns:
                 name_series = df_report[col_name].astype(str).fillna('')
            else: name_series = pd.Series([])
            
            # P10 Fix
            mask = pd.Series(False, index=df_report.index)
            if not phone_series.empty: mask |= phone_series.str.contains(s_clean, na=False)
            if not name_series.empty: mask |= name_series.str.contains(s_clean, na=False)
            results = df_report[mask].copy()
            unique_members = results[[col_name, col_phone]].drop_duplicates()
            
            if not unique_members.empty:
                st.success(f"æ‰¾åˆ° {len(unique_members)} ä½ç›¸é—œæœƒå“¡")
                unique_members['Label'] = unique_members[col_name].astype(str) + " (" + unique_members[col_phone].astype(str) + ")"
                sel_member_label = st.selectbox("è«‹é¸æ“‡:", unique_members['Label'].tolist())
                sel_row = unique_members[unique_members['Label'] == sel_member_label].iloc[0]
                sel_name = sel_row[col_name]
                sel_phone = sel_row[col_phone]
                
                if pd.isna(sel_phone): mem_records = df_report[df_report[col_name] == sel_name].copy()
                else: mem_records = df_report[(df_report[col_name] == sel_name) & (df_report[col_phone] == sel_phone)].copy()
                mem_records = mem_records.sort_values('Datetime', ascending=False)
                
                st.divider()
                st.subheader(f"ğŸ“„ {sel_name} çš„æ¶ˆè²»ç´€éŒ„")
                
                total_spend = mem_records['ç¸½è¨ˆ'].sum()
                # P11: Visit Count based on Unique Date (Same day = 1 visit)
                real_visit_count = mem_records['Date_Parsed'].nunique()
                tx_count = len(mem_records)
                
                avg_spend = total_spend / real_visit_count if real_visit_count > 0 else 0
                
                m1, m2, m3, m4 = st.columns(4)
                m1.metric("ç¸½æ¶ˆè²»", f"${total_spend:,.0f}")
                m2.metric("ä¾†åº—æ¬¡æ•¸ (Days)", f"{real_visit_count} å¤©")
                m3.metric("ç¸½å–®æ•¸ (Txs)", f"{tx_count} å¼µ")
                m4.metric("å¹³å‡å®¢å–® (Per Day)", f"${avg_spend:,.0f}")
                
                st.write("**è©³ç´°äº¤æ˜“åˆ—è¡¨**")
                st.dataframe(mem_records[['Datetime', 'ç¸½è¨ˆ', 'å–®é¡å‹']], use_container_width=True)
            else: st.warning("æŸ¥ç„¡è³‡æ–™")

    # --- VIEW 4: æ™ºæ…§é æ¸¬ ---
    elif view_mode == "ğŸ”® æ™ºæ…§é æ¸¬":
        st.title("ğŸ”® AI ç‡Ÿæ”¶èˆ‡éŠ·é‡é æ¸¬")
        
        # P11: New Revenue Logic
        avg_wd, avg_hd = predict_revenue_summary(df_report)
        st.subheader("ğŸ“Š é æ¸¬åŸºç¤ (éå» 2 é€±å¹³å‡)")
        c1, c2 = st.columns(2)
        c1.metric("å¹³æ—¥æ—¥å‡ç‡Ÿæ”¶ (Weekday Avg)", f"${avg_wd:,.0f}")
        c2.metric("å‡æ—¥æ—¥å‡ç‡Ÿæ”¶ (Holiday Avg)", f"${avg_hd:,.0f}")
        
        st.divider()
        st.subheader("ğŸ“… æœªä¾† 12 å€‹æœˆç‡Ÿæ”¶é æ¸¬è¡¨")
        latest_date = df_report['Date_Parsed'].max()
        forecast_df = predict_monthly_table(avg_wd, avg_hd, latest_date, months=12)
        
        # Display Table: Month, WD Days, HD Days, Forecast Rev
        st.dataframe(forecast_df.style.format({
            'Forecast Revenue': '${:,.0f}'
        }), use_container_width=True)
        
        # Chart
        fig_rev = px.bar(forecast_df, x='Month', y='Forecast Revenue', title="æœªä¾† 12 å€‹æœˆé ä¼°ç‡Ÿæ”¶")
        st.plotly_chart(fig_rev, use_container_width=True)

except Exception as e: st.error(f"ç³»çµ±éŒ¯èª¤: {e}")
