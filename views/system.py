import streamlit as st
import pandas as pd

def render_system_check(debug_logs, df_report, df_details):
    st.title("ğŸ”§ ç³»çµ±æª¢æŸ¥ (System Diagnostics)")
    
    st.subheader("1. è³‡æ–™è¼‰å…¥æ—¥èªŒ (Data Loader Logs)")
    if debug_logs:
        log_text = "\n".join(debug_logs)
        st.text_area("Loader Logs", log_text, height=300)
    else:
        st.info("ç„¡æ—¥èªŒ (No logs available)")
        
    st.subheader("2. è³‡æ–™çµ±è¨ˆ (Data Stats)")
    c1, c2 = st.columns(2)
    c1.metric("Report Rows", len(df_report))
    c2.metric("Details Rows", len(df_details))
    
    if not df_details.empty:
        st.subheader("3. å ±è¡¨è³‡æ–™é è¦½ (Report Preview)")
        st.dataframe(df_report.head(50), use_container_width=True)
        
    # --- Main Dish Inspector (v2.3.6 Debug Tool) ---
    st.divider()
    st.subheader("ğŸ•µï¸â€â™€ï¸ ä¸»é£Ÿåˆ¤å®šæª¢æŸ¥å™¨ (Main Dish Inspector)")
    
    # Date Picker for inspection
    insp_date = st.date_input("é¸æ“‡æª¢æŸ¥æ—¥æœŸ", pd.to_datetime("2025-02-15"))
    insp_date = pd.to_datetime(insp_date)
    
    if 'Date_Parsed' in df_details.columns:
        # Filter by Date
        # Use Date_Only for comparison
        df_d_day = df_details[df_details['Date_Parsed'].dt.date == insp_date.date()].copy()
        
        st.write(f"ğŸ“… **æ—¥æœŸ:** {insp_date.strftime('%Y-%m-%d')}")
        st.write(f"ğŸ”¢ **ç•¶æ—¥ç¸½æ˜ç´°è¡Œæ•¸:** {len(df_d_day)}")
        
        if not df_d_day.empty:
            # 1. Included Main Dishes
            if 'Is_Main_Dish' in df_d_day.columns:
                df_main = df_d_day[df_d_day['Is_Main_Dish']].copy()
                st.metric("ğŸœ ä¸»é£Ÿç¸½æ•¸ (Qty Sum)", f"{df_main['qty'].sum():.0f}", help="æ‰€æœ‰ç¬¦åˆæ¢ä»¶å“é …çš„æ•¸é‡åŠ ç¸½")
                
                with st.expander("âœ… è¢«åˆ¤å®šç‚ºã€Œä¸»é£Ÿã€çš„é …ç›® (Included)", expanded=True):
                    if not df_main.empty:
                        # Group for cleaner view
                        disp = df_main.groupby(['item_name', 'sku', 'unit_price', 'status']).agg({'qty': 'sum'}).reset_index()
                        st.dataframe(disp, use_container_width=True)
                    else:
                        st.warning("æ­¤æ—¥æœŸæ²’æœ‰ä»»ä½•ä¸»é£Ÿè¢«è¨ˆç®—åˆ°ã€‚")
            
            # 2. Excluded Candidates (Debug)
            # Find items that match SKU/Name rules but Is_Main_Dish is False
            # Re-run strict logic parts to see why failed
            
            # Re-construct logic locally for debug display
            # Condition: SKU A/B OR Name éºµ/é£¯
            sku_s = df_d_day['sku'].fillna('').astype(str).str.upper().str.strip()
            name_s = df_d_day['item_name'].fillna('').astype(str)
            
            cond_sku = sku_s.str.startswith(('A', 'B')) & (sku_s != '')
            cond_name = name_s.str.contains('éºµ|é£¯', regex=True, na=False)
            is_candidate = np.where(sku_s != '', cond_sku, cond_name) # Same as loader logic
            
            # Filter: Candidate BUT NOT Main Dish
            df_excluded = df_d_day[is_candidate & (~df_d_day['Is_Main_Dish'])].copy()
            
            with st.expander("ğŸš« è¢«æ’é™¤çš„æ½›åœ¨ä¸»é£Ÿ (Excluded Candidates) - è«‹æª¢æŸ¥åŸå› ", expanded=True):
                if not df_excluded.empty:
                    st.write("é€™äº›é …ç›®ç¬¦åˆã€ŒSKU A/Bã€æˆ–ã€Œéºµ/é£¯ã€ï¼Œä½†è¢«æ’é™¤äº†ã€‚åŸå› å¯èƒ½æ˜¯ï¼š")
                    st.write("1. ç‹€æ…‹æ˜¯ Cancelled/Void (Loader å·²éæ¿¾ï¼Œæ‰€ä»¥é€™è£¡å¯èƒ½çœ‹ä¸åˆ°ï¼Œé™¤éLoaderé‚è¼¯æœ‰æ¼)")
                    st.write("2. æ˜¯ Combo Item")
                    st.write("3. ç¨‹å¼é‚è¼¯éŒ¯èª¤")
                    
                    st.dataframe(df_excluded[['item_name', 'sku', 'qty', 'status', 'item_type', 'order_type', 'Is_Modifier']], use_container_width=True)
                else:
                    st.info("æ²’æœ‰ä»»ä½•ã€Œç¬¦åˆç‰¹å¾µä½†è¢«æ’é™¤ã€çš„é …ç›®ã€‚ (ä»£è¡¨å‰©ä¸‹çš„éƒ½æ˜¯å®Œå…¨ä¸ç›¸é—œçš„é…èœ/é£²æ–™)")
                    
            # 3. All items breakdown
            with st.expander("ğŸ“‹ ç•¶æ—¥æ‰€æœ‰æ˜ç´° (åŸå§‹è³‡æ–™)", expanded=False):
                st.dataframe(df_d_day, use_container_width=True)
                
    else:
        st.error("Data missing 'Date_Parsed' column.")

    st.divider()
    st.subheader("5. ä¼ºæœå™¨æª”æ¡ˆåˆ—è¡¨ (Server File System)")
    
    import os
    import time
    from config import DATA_DIRS
    
    # Scan all configured paths
    found_files = []
    for d in DATA_DIRS:
        if os.path.exists(d):
            st.write(f"ğŸ“ Directory found: `{d}`")
            try:
                for root, dirs, files in os.walk(d):
                    for file in files:
                        if file.lower().endswith(('.csv', '.xls', '.xlsx')):
                            full_path = os.path.join(root, file)
                            stat = os.stat(full_path)
                            size_mb = stat.st_size / (1024 * 1024)
                            mod_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(stat.st_mtime))
                            found_files.append({
                                "Path": full_path,
                                "File": file,
                                "Size (MB)": f"{size_mb:.2f}",
                                "Modified": mod_time
                            })
            except Exception as e:
                st.error(f"Error scanning {d}: {e}")
        else:
            st.warning(f"âŒ Directory not found: `{d}`")
            
    if found_files:
        df_files = pd.DataFrame(found_files)
        st.dataframe(df_files, use_container_width=True)
        
        # File Inspector
        st.subheader("6. æª”æ¡ˆå…§å®¹æª¢æŸ¥ (File Inspector)")
        selected_file = st.selectbox("é¸æ“‡æª”æ¡ˆé€²è¡Œæª¢æŸ¥ (Select File to Inspect)", df_files['Path'].unique())
        
        if selected_file:
            if st.button(f"è®€å– {os.path.basename(selected_file)} å‰ 5 è¡Œ"):
                try:
                    if selected_file.endswith('.csv'):
                        # Try reading raw first to show columns
                        df_preview = pd.read_csv(selected_file, nrows=5)
                        st.write("Columns:", df_preview.columns.tolist())
                        st.dataframe(df_preview)
                    else:
                        st.info("Excel file preview not fully supported in this quick view yet.")
                except Exception as e:
                    st.error(f"Error reading file: {e}")
    else:
        st.warning("No data files found in scan paths.")
